# DASC7606 Final - summerized by hyperloop

# Section 0 Scope

![S](./Scope.png)

# Section 1 DeepLearning Basis

## Q1 2025 May

![Q1](./2025May/1.png)
![Q1](./2025May/2.png)

## Answer

### (a)

- Tanhï¼štanh (0) = 0ï¼ŒèŒƒå›´ (-1, 1) âœ…
- Sineï¼šsin (0) = 0ï¼ŒèŒƒå›´ [-1, 1] âœ…
- Sigmoidï¼šg(0) = 0.5 âŒ
- ReLUï¼šg (0) = 0ï¼Œä¸å¯¹ç§°ã€éžè´Ÿ âŒï¼ˆé€šå¸¸ â€œé›¶ä¸­å¿ƒâ€ æŒ‡å‡å€¼ 0ï¼ŒReLU è¾“å‡ºå‡å€¼ > 0ï¼‰
- SiLU: åœ¨è¾“å…¥å‡å€¼ä¸º 0 æ—¶è¾“å‡ºå‡å€¼æŽ¥è¿‘ 0 ä½†ç•¥æ­£ï¼Œæ‰€ä»¥ä¸€èˆ¬ä¸ä¸¥æ ¼ç®—é›¶ä¸­å¿ƒã€‚

### (b)

- ReLUï¼šéžå¸¸å¿« âœ…
- Sineï¼šéœ€è¦ç®— sinï¼Œè¾ƒæ…¢ âŒ
- Sigmoidã€Tanhï¼šæœ‰æŒ‡æ•°ï¼Œæ…¢ âŒ
- SiLUï¼šæœ‰ sigmoid å’Œä¹˜æ³•ï¼Œæ¯” ReLU æ…¢ âŒ

### (c)

Sigmoid, Tanh, Sine

### (d)

Sigmoid, Tanh, ReLU

### (e)

å‡½æ•°å®šä¹‰Swish_Î²(x) = xãƒ»Ïƒ(Î²x)ï¼ˆÏƒ ä¸º sigmoid å‡½æ•°ï¼‰

ä¸åŒ Î² å€¼çš„å‡½æ•°ç‰¹æ€§

- Î²=0ï¼šå‡½æ•° = xãƒ»1/2 = x/2ï¼Œå‘ˆçº¿æ€§å…³ç³»ã€‚
- Î²=1ï¼šå³ SiLU å‡½æ•°ï¼Œå…·å¤‡å…‰æ»‘ã€éžå•è°ƒï¼ˆè´ŸåŒºæœ‰ä¸‹å‡¸ç‰¹æ€§ï¼‰ã€é›¶èµ·ç‚¹ã€æœ‰è´Ÿè¾“å‡ºçš„ç‰¹ç‚¹ã€‚
- Î²â†’âˆžï¼šå‡½æ•°è¶‹è¿‘äºŽ ReLUï¼Œå›  sigmoid å‡½æ•°è¶‹è¿‘äºŽé˜¶è·ƒå‡½æ•°ã€‚

æ ¸å¿ƒä¼˜åŠ¿

- å…‰æ»‘æ€§ï¼šåœ¨ x=0 å¤„å¯å¯¼ï¼Œç›¸æ¯” ReLU èƒ½è®©è®­ç»ƒæ›´ç¨³å®šã€‚
- éžå•è°ƒæ€§ï¼šè´ŸåŒºå­˜åœ¨å°è´Ÿå³°ï¼Œæœ‰åŠ©äºŽæ¢¯åº¦ä¼ æ’­ï¼Œå¯é˜²æ­¢ â€œæ­»ç¥žç»å…ƒâ€ï¼Œæ•ˆæžœç±»ä¼¼ Leaky ReLU ä½†æ›´å…·è‡ªé€‚åº”æ€§ã€‚
- æ¸è¿›è¡Œä¸ºï¼šå¤§æ­£æ•°è¾“å…¥æ—¶å‘ˆçº¿æ€§ç‰¹å¾ï¼Œå¤§è´Ÿæ•°è¾“å…¥æ—¶è¶‹è¿‘äºŽ 0ï¼Œä¸”è´ŸåŒºå¹¶éžå®Œå…¨ä¸ºé›¶ï¼Œå…è®¸æ¢¯åº¦å›žæµã€‚
- é€‚åº”æ€§ï¼šÎ² ä¸ºå¯è®­ç»ƒå‚æ•°ï¼Œèƒ½è‡ªåŠ¨è°ƒèŠ‚çº¿æ€§ä¸Žé¥±å’ŒçŠ¶æ€ä¹‹é—´çš„å¹³è¡¡ã€‚
- ç»éªŒæ€§èƒ½ï¼šåœ¨æ·±å±‚ç½‘ç»œæµ‹è¯•ä¸­ï¼ŒSwish è¡¨çŽ°å¸¸ä¼˜äºŽ ReLUã€‚

## Summerization for Activation Function æ¿€æ´»å‡½æ•°å¯¹æ¯”æ€»ç»“

| æ¿€æ´»å‡½æ•°             | å…¬å¼                            | å¯¼æ•°                       | é›¶ä¸­å¿ƒ     | è®¡ç®—æ•ˆçŽ‡ | å•è°ƒæ€§   | å½’ä¸€åŒ–/ç¼©æ”¾æ•°æ® | å…¶ä»–ç‰¹æ€§                                                                               |
| -------------------- | ------------------------------- | -------------------------- | ---------- | -------- | -------- | --------------- | -------------------------------------------------------------------------------------- |
| **Sigmoid**    | `1/(1+e^(-x))`                | `f(x)(1-f(x))`           | âŒ         | ä½Ž       | âœ…       | âœ… (0,1)        | æ˜“æ¢¯æ¶ˆå¤±ï¼Œè¾“å‡ºéžé›¶ä¸­å¿ƒ                                                                 |
| **Tanh**       | `tanh(x)`                     | `1 - tanhÂ²(x)`          | âœ…         | ä½Ž       | âœ…       | âœ… (-1,1)       | é›¶ä¸­å¿ƒç‰ˆSigmoidï¼Œæ¢¯åº¦æ¶ˆå¤±                                                              |
| **ReLU**       | `max(0, x)`                   | `1 (x>0), 0 (x<0)`       | âŒ         | é«˜       | âœ…       | âŒ              | å¤§äºŽ0æ— æ¢¯åº¦æ¶ˆå¤±ï¼Œå°äºŽ0ä»æœ‰ï¼›æ”¶æ•›æ›´å¿«ï¼›é€‚ç”¨CNN                                          |
| **Leaky ReLU** | `max(Î±x, x)`                 | `1 (x>0), Î± (x<0)`      | âŒ         | é«˜       | âœ…       | âŒ              | All benefits of ReLU; Closer to zero-centered outputs; Non-zero gradient when negative |
| **ELU**        | `x (xâ‰¥0), Î±(e^x-1) (x<0)`   | `1 (x>0), f(x)+Î± (x<0)` | âŒ         | ä½Ž       | âœ…       | âŒ              | Similar to leaky ReLu; Differentiable at 0 when ð›¼=1                                   |
| **Maxout**     | `max(wâ‚áµ€x+bâ‚, wâ‚‚áµ€x+bâ‚‚)` | åˆ†æ®µå¸¸æ•°                   | å–å†³äºŽå‚æ•° | è¾ƒä½Ž     | âœ…       | âŒ              | å¯æ‹Ÿåˆå‡¸åˆ†æ®µçº¿æ€§å‡½æ•°ï¼Œå‚æ•°å¤š                                                           |
| **SiLU/Swish** | `x Â· Ïƒ(x)`                  | `Ïƒ(x)(1 + x(1-Ïƒ(x)))`  | è¿‘ä¼¼é›¶ä¸­å¿ƒ | ä¸­       | âŒ       | âŒ              | å…‰æ»‘ã€éžå•è°ƒè´ŸåŒºï¼Œè‡ªé—¨æŽ§                                                               |
| **Swish (Î²)** | `x Â· Ïƒ(Î²x)`                | ç±»ä¼¼SiLUï¼Œä¾èµ–Î²           | è¿‘ä¼¼é›¶ä¸­å¿ƒ | ä¸­       | å–å†³äºŽÎ² | âŒ              | Î²å¯è°ƒï¼ŒÎ²â†’0çº¿æ€§ï¼ŒÎ²â†’âˆžä¼¼ReLU                                                        |

## Key Features Explaination å…³é”®ç‰¹æ€§è¯´æ˜Ž

### é›¶ä¸­å¿ƒ (Zero-centred)

- **ä¸¥æ ¼é›¶ä¸­å¿ƒ**ï¼šTanh
- **è¿‘ä¼¼é›¶ä¸­å¿ƒ**ï¼šSiLU/Swishï¼ˆåŽŸç‚¹ä¸º0ï¼Œè´ŸåŒºæœ‰è¾“å‡ºä½†ä¸å¯¹ç§°ï¼‰
- **éžé›¶ä¸­å¿ƒ**ï¼šSigmoid, ReLU, Leaky ReLU, ELU

### è®¡ç®—æ•ˆçŽ‡

- **é«˜**ï¼šReLU, Leaky ReLUï¼ˆç®€å•æ¯”è¾ƒå’Œä¹˜æ³•ï¼‰
- **ä¸­**ï¼šSigmoid, Tanh, ELU, SiLUï¼ˆæ¶‰åŠæŒ‡æ•°è¿ç®—ï¼‰
- **è¾ƒä½Ž**ï¼šMaxoutï¼ˆéœ€è¦å¤šä¸ªçº¿æ€§è®¡ç®—å’Œæ¯”è¾ƒï¼‰

### å•è°ƒæ€§

- **å•è°ƒ**ï¼šSigmoid, Tanh, ReLU, Leaky ReLU, ELU, Maxout
- **éžå•è°ƒ**ï¼šSiLU/Swishï¼ˆåœ¨è´ŸåŒºæœ‰ä¸‹å‡¸"é©¼å³°"ï¼‰

### æ•°æ®ç¼©æ”¾èƒ½åŠ›

- **èƒ½ç¼©æ”¾**ï¼šSigmoid â†’ (0,1), Tanh â†’ (-1,1)
- **ä¸èƒ½ç¼©æ”¾**ï¼šReLUç³»åˆ—, SiLU, Maxoutï¼ˆè¾“å‡ºæ— ç•Œï¼‰

### å…¶ä»–é‡è¦ç‰¹æ€§

- **æ¢¯åº¦é¥±å’Œ**ï¼šSigmoid, Tanhï¼ˆåœ¨æžç«¯å€¼å¤„æ¢¯åº¦æŽ¥è¿‘0ï¼‰
- **æ­»ç¥žç»å…ƒ**ï¼šReLUï¼ˆè´ŸåŒºæ¢¯åº¦ä¸º0ï¼‰
- **ç¼“è§£æ­»ç¥žç»å…ƒ**ï¼šLeaky ReLU, ELU, SiLU
- **å…‰æ»‘æ€§**ï¼šELU, SiLUï¼ˆå¤„å¤„å¯å¯¼ï¼‰
- **å‚æ•°æ•ˆçŽ‡**ï¼šMaxoutå‚æ•°æœ€å¤šï¼ŒReLUå‚æ•°æœ€å°‘

---

## Q2 2024 May ABC

![Q2](./2024MayABC/6.jpg)
![Q2](./PPT2/2.png)

### Common Loss/Cost Functions Table

å¥½çš„ï¼Œå·²ä¸ºæ‚¨å°†å†…å®¹æ•´ç†ä¸ºå®Œæ•´çš„Markdownè¡¨æ ¼ã€‚

| Task Type              | Loss Function                   | Formula                                                                                                    | Output Activation | Key Characteristic                                                                                                       |
| :--------------------- | :------------------------------ | :--------------------------------------------------------------------------------------------------------- | :---------------- | :----------------------------------------------------------------------------------------------------------------------- |
| Regression             | Mean Squared Error (MSE)        | $J = \frac{1}{N} \sum_{i=1}^{N} (y_i - \tilde{y}_i)^2$                                                   | Linear (Identity) | Penalizes large errors quadratically; sensitive to outliers.                                                             |
| Regression             | Mean Absolute Error (MAE)       | $J = \frac{1}{N} \sum_{i=1}^{N} \|y_i - \tilde{y}_i\|$                                                   | Linear (Identity) | Measures the average absolute difference; more robust to outliers than MSE.                                              |
| Binary Classification  | Binary Cross-Entropy (Log Loss) | $J = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\tilde{y}_i) + (1 - y_i) \log(1 - \tilde{y}_i) \right]$ | Sigmoid           | Measures the dissimilarity between two probability distributions (the true label$y$ and the prediction $\tilde{y}$). |
| Multi-Class Classifica | Categorical Cross-Entropy       | $J = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{i,c} \log(\tilde{y}_{i,c})$                           | Softmax           | Used when labels are one-hot encoded. Standard for tasks with more than two classes.                                     |

## Q3 2024 May ABC

![Q3](./2024MayABC/7.png)

## Answer

### (1)

i. å¢žåŠ ç½‘ç»œè§„æ¨¡
âŒ ä¼šä½¿è¿‡æ‹Ÿåˆæ›´ä¸¥é‡ï¼ˆæ¨¡åž‹å®¹é‡æ›´å¤§ï¼Œæ›´å®¹æ˜“è®°ä½è®­ç»ƒé›†ï¼‰ã€‚
ii. æ•°æ®å¢žå¼º
âœ… å¢žåŠ è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚
iii. æ—©åœ
âœ… é˜²æ­¢æ¨¡åž‹åœ¨è®­ç»ƒé›†ä¸Šè¿‡åº¦ä¼˜åŒ–ï¼Œæå‡æ³›åŒ–ã€‚
iv. ä½¿ç”¨ ReLU
â“ å¯èƒ½å¯¹æ¢¯åº¦æµåŠ¨æœ‰å¸®åŠ©ï¼Œä½†ä¸ç›´æŽ¥è§£å†³è¿‡æ‹Ÿåˆï¼Œç”šè‡³å¯èƒ½å› ç¨€ç–æ¿€æ´»ç•¥å¾®å½±å“ï¼Œä½†ä¸»è¦ä¸æ˜¯é’ˆå¯¹è¿‡æ‹Ÿåˆçš„å¸¸è§„é¦–é€‰æ–¹æ³•ã€‚é€šå¸¸ ReLU ä»£æ›¿ sigmoid æ˜¯ä¸ºäº†ç¼“è§£æ¢¯åº¦æ¶ˆå¤±ï¼Œä¸æ˜¯ä¸»è¦è§£å†³è¿‡æ‹Ÿåˆï¼Œæ‰€ä»¥ä¸€èˆ¬ä¸é€‰æ­¤é¡¹ã€‚
v. dropout åœ¨è®­ç»ƒå’Œæµ‹è¯•æ—¶åº”ç”¨æ–¹å¼ä¸åŒ
âœ… Dropout åœ¨è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒç¥žç»å…ƒï¼Œæµ‹è¯•æ—¶ä¸ä¸¢å¼ƒï¼ˆä½†ç¼©æ”¾æƒé‡ï¼‰ï¼Œè¿™æœ¬èº«å°±æ˜¯æ­£åˆ™åŒ–æ–¹æ³•ï¼Œèƒ½å‡å°‘è¿‡æ‹Ÿåˆã€‚
vi. æ”¹å˜æŸå¤±å‡½æ•°ï¼Œè§£é‡Šå¦‚ä½•æ”¹
âœ… ä¾‹å¦‚åŠ å…¥ L2 æ­£åˆ™åŒ–é¡¹ï¼ˆæƒé‡è¡°å‡ï¼‰æˆ– L1 æ­£åˆ™åŒ–

### (2)

è®­ç»ƒè¯¯å·®æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ ä¸Šæ­£åˆ™åŒ–é¡¹ï¼ˆå¦‚ dropoutï¼‰è®¡ç®—çš„ï¼Œè€Œæµ‹è¯•æ—¶æ²¡æœ‰ dropout ç­‰ï¼Œæ¨¡åž‹è¡¨çŽ°æ›´å¥½ã€‚
è®­ç»ƒé›†ä¸Žæµ‹è¯•é›†åˆ†å¸ƒä¸åŒï¼Œæµ‹è¯•é›†æ ·æœ¬æ›´ç®€å•æˆ–å™ªå£°æ›´å°‘ã€‚
è®­ç»ƒè¯¯å·®æ˜¯åœ¨æ¯ä¸ª epoch ä¸­è®¡ç®—çš„ï¼Œå¯èƒ½åŒ…å«è¿˜åœ¨å­¦ä¹ çš„é«˜å™ªå£°æ—¶æ®µï¼Œè€Œæµ‹è¯•è¯¯å·®æ˜¯åœ¨æ¨¡åž‹æ”¶æ•›åŽåœ¨ä¸€ä¸ªå¹²å‡€æµ‹è¯•é›†ä¸Šé‡çš„ã€‚
è®­ç»ƒé›†æ•°æ®é¢„å¤„ç†ï¼ˆå¦‚æ•°æ®å¢žå¼ºï¼‰ ä½¿è®­ç»ƒä»»åŠ¡å˜éš¾ï¼Œä½†æµ‹è¯•æ—¶æ²¡æœ‰å¢žå¼ºï¼Œæ‰€ä»¥æµ‹è¯•è¯¯å·®æ›´ä½Žã€‚

Training error is calculated during training with regularization terms (e.g., dropout), while testing is done without dropout, so the model performs better.
The distribution of the training set and test set may differâ€”the test set samples could be simpler or have less noise.
Training error is computed at each epoch and may include high-noise periods when the model is still learning, whereas test error is measured on a clean test set after the model has converged.
Data preprocessing (e.g., data augmentation) on the training set makes the task harder, but no augmentation is applied during testing, leading to lower test error.

### (3)

å°æ‰¹é‡æ—¶ï¼Œæ¯æ¬¡æ›´æ–°æ¢¯åº¦å™ªå£°å¤§ï¼Œæ–¹å‘ä¸ç¨³å®šï¼Œéœ€è¦æ›´å¤šå°æ­¥æ‰èƒ½é€¼è¿‘æœ€ä¼˜ã€‚
å¢žå¤§ batch size ä½¿æ¢¯åº¦ä¼°è®¡æ›´å‡†ç¡®ï¼Œæ¯æ¬¡æ›´æ–°æ›´æŽ¥è¿‘çœŸå®žæ¢¯åº¦æ–¹å‘ï¼Œæ‰€ä»¥éœ€è¦æ›´å°‘çš„è¿­ä»£æ¬¡æ•°åˆ°è¾¾ç›®æ ‡æŸå¤±ã€‚
With small batch sizes, each gradient update has high noise and an unstable direction, requiring more small steps to approach the optimum.
Increasing the batch size makes the gradient estimate more accurate, with each update closer to the true gradient direction, thus requiring fewer iterations to reach the target loss.

### (4)

å½“ batch size è¶³å¤Ÿå¤§æ—¶ï¼ˆæ¯”å¦‚è¶…è¿‡æŸä¸ªç‚¹ï¼‰ï¼Œæ¢¯åº¦ä¼°è®¡å·²ç»éžå¸¸æŽ¥è¿‘å…¨æ‰¹é‡æ¢¯åº¦ï¼Œç»§ç»­å¢žå¤§ batch size å¯¹æ¢¯åº¦æ–¹å‘å‡†ç¡®åº¦æå‡å¾ˆå°ã€‚
æ­¤æ—¶ä¸»è¦å—ä¼˜åŒ–ç®—æ³•ã€å­¦ä¹ çŽ‡ã€æ¨¡åž‹æž¶æž„ç­‰é™åˆ¶ï¼Œè¿­ä»£æ¬¡æ•°è¶‹äºŽç¨³å®šã€‚

## Q4 2024 Dec ABD

![Q4](./2024DecABD/1.jpg)
![Q4](./2024DecABD/2.jpg)

## Q5 2024 Dec ABD

![Q5](./2024DecABD/4.jpg)
![Q5](./2024DecABD/4-1.png)
![Q5](./2024DecABD/4-2.png)

## Q6 2024 Dec C

![Q6](./2024DecC/1.png)

### Answer

### (a) é›¶ä¸­å¿ƒæ¿€æ´»å‡½æ•°çš„ä¼˜åŠ¿

å¦‚æžœè¾“å‡ºæ˜¯é›¶ä¸­å¿ƒçš„ï¼Œæ¢¯åº¦ä¸‹é™ä¼šè¢«é™åˆ¶åœ¨â€œå¥½â€çš„æ–¹å‘ï¼Œä»Žè€Œæ”¶æ•›æ›´å¿«
â†’ ä¸å®Œå…¨å‡†ç¡®ï¼Œé›¶ä¸­å¿ƒä¸»è¦ä½¿æ¢¯åº¦æ–¹å‘æ›´åˆç†ï¼Œä½†ä¸æ˜¯â€œé™åˆ¶â€æ–¹å‘ï¼Œè€Œæ˜¯é¿å… zig-zag æ›´æ–°ï¼ˆå½“æ‰€æœ‰è¾“å…¥ä¸ºæ­£æ—¶ï¼Œæƒé‡æ¢¯åº¦åŒå·ï¼Œæ›´æ–°è·¯å¾„å·®ï¼‰ã€‚æ‰€ä»¥è¿™ä¸ªè¯´æ³•æœ‰ç‚¹æ¨¡ç³Šï¼Œä½†æ„å›¾æ˜¯æŒ‡é›¶ä¸­å¿ƒå¸®åŠ©ä¼˜åŒ–ã€‚

å¦‚æžœè¾“å‡ºæ˜¯é›¶ä¸­å¿ƒï¼Œæ¢¯åº¦é€šå¸¸å–æ›´å¹¿çš„å€¼ï¼Œé€šå¸¸å¯¼è‡´æ›´å¥½æ”¶æ•›
â†’ åˆç†ï¼Œé›¶ä¸­å¿ƒä½¿æ¢¯åº¦æœ‰æ­£æœ‰è´Ÿï¼Œæ›´æ–°æ›´çµæ´»ã€‚

å› ä¸ºè¿™è§£å†³äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
â†’ é”™è¯¯ï¼Œé›¶ä¸­å¿ƒä¸èƒ½ç›´æŽ¥è§£å†³æ¢¯åº¦æ¶ˆå¤±ï¼ˆè¿™æ›´å¤šä¸Žå¯¼æ•°å¹…åº¦ã€æƒé‡åˆå§‹åŒ–ã€ç½‘ç»œç»“æž„æœ‰å…³ï¼‰ã€‚

å¦‚æžœæ¿€æ´»å‡½æ•°è¾“å‡ºå…¨æ­£ï¼Œä¸”æ¿€æ´»å‡½æ•°æ˜¯çº¿æ€§çš„ï¼Œé‚£ä¹ˆæ¢¯åº¦è¦ä¹ˆå…¨éžæ­£è¦ä¹ˆå…¨éžè´Ÿ
â†’ æ­£ç¡®ï¼Œè¿™æ˜¯é›¶ä¸­å¿ƒé‡è¦æ€§çš„ä¸€ä¸ªå…³é”®åŽŸå› ï¼šè‹¥è¾“å…¥å…¨æ­£ï¼Œåˆ™æŸæƒé‡çš„æ¢¯åº¦ç¬¦å·å–å†³äºŽä¸Šä¸€å±‚è¯¯å·®é¡¹ï¼Œå¯èƒ½æ‰€æœ‰æ ·æœ¬å¯¹è¯¥æƒé‡çš„æ¢¯åº¦åŒå·ï¼Œå¯¼è‡´æƒé‡æ›´æ–°åªèƒ½æ²¿ç‰¹å®šæ–¹å‘æ›²æŠ˜å‰è¿›ï¼Œæ”¶æ•›æ…¢ã€‚

å› ä¸ºè¿™ä¿è¯æ²¡æœ‰è¿‡æ‹Ÿåˆ
â†’ é”™è¯¯ï¼Œé›¶ä¸­å¿ƒä¸Žè¿‡æ‹Ÿåˆæ— ç›´æŽ¥å¿…ç„¶è”ç³»ã€‚

æ­£ç¡®é€‰é¡¹ï¼š1, 2, 4

### (b) åå‘ä¼ æ’­ç›¸å…³è¯´æ³•

åå‘ä¼ æ’­ç®—æ³•èƒ½é«˜æ•ˆè®¡ç®—ç¥žç»ç½‘ç»œä¸­çš„æ¢¯åº¦
â†’ æ­£ç¡®ï¼Œè¿™æ­£æ˜¯ BP çš„æ ¸å¿ƒä½œç”¨ã€‚

åå‘ä¼ æ’­åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µè®¡ç®—æ¢¯åº¦ï¼Œç¬¬äºŒé˜¶æ®µé€šå¸¸è¿è¡Œä¸€æ­¥æ¢¯åº¦ä¸‹é™ï¼Œè¿™é€šå¸¸å¯¼è‡´åŽè€…æ›´å¥½æ”¶æ•›
â†’ é”™è¯¯ï¼Œä¸¤ä¸ªé˜¶æ®µæ˜¯å‰å‘ä¼ æ’­ï¼ˆç®—è¾“å‡ºï¼‰å’Œåå‘ä¼ æ’­ï¼ˆç®—æ¢¯åº¦ï¼‰ï¼Œæ¢¯åº¦ä¸‹é™æ˜¯ä¼˜åŒ–æ­¥éª¤ï¼Œä¸æ˜¯ BP çš„ä¸€éƒ¨åˆ†ã€‚

åå‘ä¼ æ’­å¯ä»¥é«˜æ•ˆå¹¶è¡ŒåŒ–ï¼šæ­¤æ—¶è¿è¡Œæ—¶é—´ä¸ä¾èµ–äºŽç½‘ç»œå±‚æ•°ï¼Œè€Œåªä¾èµ–äºŽ GPU æ•°é‡
â†’ é”™è¯¯ï¼Œå³ä½¿å¹¶è¡Œï¼Œæ¯å±‚ä¾èµ–å‰ä¸€å±‚çš„æ¢¯åº¦ï¼Œæ‰€ä»¥æ—¶é—´ä»ä¸Žå±‚æ•°æœ‰å…³ï¼Œä¸èƒ½å®Œå…¨å¹¶è¡Œæ‰€æœ‰å±‚ã€‚

æ­£ç¡®é€‰é¡¹ï¼š1

### (c) ResNet ç›¸å…³è¯´æ³•

ResNet çš„ä¸»è¦ç›®æ ‡æ˜¯ä»»æ„é€¼è¿‘æ’ç­‰å‡½æ•°ã€‚å› ä¸ºå¤§å¤šæ•°çŽ°å®žé—®é¢˜å¯ç”±æ’ç­‰å‡½æ•°è¿‘ä¼¼ï¼ŒResNet ç»“æžœå¾ˆå¥½
â†’ é”™è¯¯ï¼ŒResNet ç¡®å®žè®©ç½‘ç»œå®¹æ˜“å­¦ä¹ æ’ç­‰æ˜ å°„ï¼Œä½†è¿™ä¸æ˜¯å› ä¸ºçŽ°å®žé—®é¢˜è¿‘ä¼¼æ’ç­‰ï¼Œè€Œæ˜¯ä¸ºäº†ç¼“è§£æ·±å±‚ç½‘ç»œé€€åŒ–é—®é¢˜ã€‚

æ›´æ·±çš„ç½‘ç»œåº”æä¾›æ›´å¥½çš„è®­ç»ƒå’Œæµ‹è¯•è¯¯å·®ï¼Œä½†å®ƒä»¬æ›´éš¾è®­ç»ƒ
â†’ æ­£ç¡®ï¼Œè¿™æ˜¯ ResNet æå‡ºçš„åŠ¨æœºï¼šç†è®ºä¸Šæ›´æ·±ç½‘ç»œè¡¨è¾¾èƒ½åŠ›æ›´å¼ºï¼Œä½†æ™®é€šç½‘ç»œåŠ æ·±æ—¶è®­ç»ƒè¯¯å·®åè€Œä¸Šå‡ï¼ˆé€€åŒ–é—®é¢˜ï¼‰ã€‚

ResNet ç¼“è§£äº†æ·±å±‚ç½‘ç»œå­¦ä¹ æ’ç­‰å‡½æ•°çš„é—®é¢˜ï¼ŒåŒæ—¶å…è®¸å­¦ä¹ æ›´å¤æ‚å‡½æ•°
â†’ æ­£ç¡®ï¼Œæ®‹å·®å—è®©ç½‘ç»œèƒ½è½»æ¾å­¦ä¹ æ’ç­‰æ˜ å°„ï¼ˆé€šè¿‡è·³è¿‡è¿žæŽ¥ï¼‰ï¼Œå¦‚æžœéœ€è¦å˜åŒ–å°±å­¦ä¹ æ®‹å·®éƒ¨åˆ†ã€‚

æ­£ç¡®é€‰é¡¹ï¼š2, 3

## Q7 2024 Dec C

![Q7](./2024DecC/2.jpg)

## Q8 2024 May D

![Q8](./2024MayD/1.png)

### Answer

### 1.1 ä¸ºä»€ä¹ˆæµ‹è¯•é›†æœ€å¥½åªç”¨ä¸€æ¬¡ï¼Ÿ

å¦‚æžœå¤šæ¬¡åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡åž‹ï¼Œå¹¶æ ¹æ®æµ‹è¯•é›†ç»“æžœè°ƒæ•´æ¨¡åž‹æˆ–è¶…å‚æ•°ï¼Œé‚£ä¹ˆæµ‹è¯•é›†ä¼šé—´æŽ¥å½±å“è®­ç»ƒè¿‡ç¨‹ï¼Œç›¸å½“äºŽæŠŠæµ‹è¯•é›†ä¿¡æ¯â€œæ³„æ¼â€åˆ°äº†æ¨¡åž‹ä¸­ã€‚è¿™æ ·æµ‹è¯•é›†å°±ä¸å†èƒ½æä¾›å¯¹æ¨¡åž‹æ³›åŒ–èƒ½åŠ›çš„æ— åä¼°è®¡ï¼Œè€Œæ˜¯ä¼šç»™å‡ºè¿‡äºŽä¹è§‚çš„ç»“æžœã€‚

ç­”æ¡ˆï¼š
ä¸ºäº†é¿å…ä¿¡æ¯æ³„æ¼ï¼ˆdata leakageï¼‰å’Œè¿‡æ‹Ÿåˆæµ‹è¯•é›†ï¼Œç¡®ä¿æµ‹è¯•é›†ç»™å‡ºå¯¹æ³›åŒ–è¯¯å·®çš„æ— åä¼°è®¡ã€‚

### 1.2 ä¸€ç§ç¼“è§£ç—…æ€æŸå¤±å‡½æ•°é—®é¢˜çš„æ¢¯åº¦ä¸‹é™å˜ä½“

ç—…æ€æŸå¤±å‡½æ•°ï¼ˆill-conditioned lossï¼‰æŒ‡ Hessian çŸ©é˜µçš„æ¡ä»¶æ•°å¾ˆå¤§ï¼Œä¸åŒæ–¹å‘æ›²çŽ‡å·®å¼‚å¤§ï¼Œå¯¼è‡´æ™®é€šæ¢¯åº¦ä¸‹é™éœ‡è¡ã€æ”¶æ•›æ…¢ã€‚

å¸¸ç”¨å˜ä½“ï¼š

åŠ¨é‡æ³•ï¼ˆMomentumï¼‰

Nesterov åŠ é€Ÿæ¢¯åº¦ï¼ˆNAGï¼‰

è‡ªé€‚åº”å­¦ä¹ çŽ‡æ–¹æ³•ï¼ˆAdaGrad, RMSProp, Adamï¼‰â€”â€”ç‰¹åˆ«æ˜¯ Adam ç»“åˆåŠ¨é‡å’Œè‡ªé€‚åº”å­¦ä¹ çŽ‡ï¼Œèƒ½è¾ƒå¥½å¤„ç†ç—…æ€é—®é¢˜ã€‚

è¯¾ç¨‹ä¸­å¸¸è§çš„æ ‡å‡†ç­”æ¡ˆæ˜¯ Momentum æˆ– Adamã€‚

### 1.3 LSTM çš„ä¸‰ä¸ªä¸»è¦é—¨

![Q8](./2024MayD/6.png)
![Q8](./2024MayD/7.png)
![Q8](./2024MayD/8.png)
![Q8](./2024MayD/9.png)
![Q8](./2024MayD/10.png)

## Q9 2023 May ABC

![Q9](./2023MayABC/1.png)
![Q9](./2023MayABC/2.png)

## Q10 2023 May D

![Q10](./2023MayD/1.png)

## Q11 2022 May 1

![Q11](./2022May1/1.png)

## Q12 2022 May 1

![Q12](./2022May1/2.png)

# Section 2 RNN & NLP

## Q1 2024 May D

![Q1](./2024MayD/4.png)
![Q1](./2024MayD/5.png)

## Q2 2023 May ABC

![Q2](./2023MayABC/5.png)
![Q2](./2023MayABC/6.png)
![Q2](./2023MayABC/7.png)

## Q3 2023 May D

![Q3](./2023MayD/4.png)
![Q3](./2023MayD/5.png)

## Q4 2022 May 2

![Q4](./2022May2/3.png)

# Section 3 Convolutional Neural Networks

## Q1 2025 May

![Q1](./2025May/9.png)
![Q1](./2025May/10.png)

### Answer

### (a) ä¸ºä»€ä¹ˆä¸‰å±‚ 3Ã—3 å·ç§¯çš„æœ‰æ•ˆæ„Ÿå—é‡Žç›¸å½“äºŽä¸€å±‚ 7Ã—7 å·ç§¯

ç¬¬ä¸€å±‚ 3Ã—3 å·ç§¯ï¼šæ¯ä¸ªè¾“å‡ºç¥žç»å…ƒçœ‹åˆ°è¾“å…¥ 3Ã—3 åŒºåŸŸã€‚

ç¬¬äºŒå±‚ 3Ã—3 å·ç§¯ï¼šæ¯ä¸ªç¥žç»å…ƒçœ‹åˆ°ç¬¬ä¸€å±‚è¾“å‡ºçš„ 3Ã—3 åŒºåŸŸï¼Œè€Œç¬¬ä¸€å±‚çš„æ¯ä¸ªç¥žç»å…ƒå¯¹åº”è¾“å…¥ 3Ã—3ï¼Œæ‰€ä»¥ç¬¬äºŒå±‚è¾“å‡ºç¥žç»å…ƒçœ‹åˆ°çš„è¾“å…¥åŒºåŸŸæ˜¯ 3 + 3 - 1 = 5Ã—5ï¼ˆä¸¤ä¸ª 3Ã—3 å·ç§¯å †å ï¼Œæœªç» padding ç¼©å°çš„æƒ…å†µï¼‰ã€‚

ç¬¬ä¸‰å±‚ 3Ã—3 å·ç§¯ï¼šåŒç†ï¼Œçœ‹åˆ°ç¬¬äºŒå±‚è¾“å‡ºçš„ 3Ã—3 åŒºåŸŸï¼Œç¬¬äºŒå±‚æ¯ä¸ªç¥žç»å…ƒå¯¹åº”è¾“å…¥ 5Ã—5ï¼Œæ‰€ä»¥ç¬¬ä¸‰å±‚è¾“å‡ºç¥žç»å…ƒçœ‹åˆ°çš„è¾“å…¥åŒºåŸŸæ˜¯ 5 + 3 - 1 = 7Ã—7ã€‚

å› æ­¤ä¸‰å±‚ 3Ã—3 å·ç§¯çš„æœ‰æ•ˆæ„Ÿå—é‡Ž = 7Ã—7ã€‚

ç­” (a)ï¼š
æ¯ä¸ª 3Ã—3 å·ç§¯å¢žåŠ  2 åˆ°æ„Ÿå—é‡Žå°ºå¯¸ï¼Œä¸‰å±‚å †å ï¼š1â†’3â†’5â†’7

### (b) ä¸ºä»€ä¹ˆä¸‰å±‚ 3Ã—3 æ¯”ä¸€å±‚ 7Ã—7 å‚æ•°å°‘

å‡è®¾è¾“å…¥è¾“å‡ºé€šé“æ•°å‡ä¸º Cã€‚

ä¸€å±‚ 7Ã—7 å·ç§¯å‚æ•°ï¼š7Ã—7Ã—CÃ—C = 49CÂ²

ä¸‰å±‚ 3Ã—3 å·ç§¯å‚æ•°ï¼šæ¯å±‚ 3Ã—3Ã—CÃ—C = 9CÂ²ï¼Œä¸‰å±‚å…± 3Ã—9CÂ² = 27CÂ²

æ˜¾ç„¶ 27CÂ² < 49CÂ²ã€‚

ç­” (b)ï¼š
27CÂ² < 49CÂ²

### (c) ä¿æŒå°ºå¯¸çš„ padding å’Œ stride

è¾“å…¥ 28Ã—28Ã—192ï¼Œè¾“å‡º 28Ã—28Ã—128ï¼Œç”¨ 3Ã—3 å·ç§¯ã€‚
è¦ä¿æŒç©ºé—´å°ºå¯¸ 28Ã—28ï¼Œéœ€è¦ padding = 1

ï¼ˆå› ä¸ºè¾“å‡ºå°ºå¯¸å…¬å¼ H_out = H_in + 2P - K / S + 1ï¼Œå½“ H_in = 28ï¼ŒK = 3ï¼ŒS = 1ï¼Œè¦ H_out = 28ï¼Œåˆ™ 28 = 28 + 2P - 3 + 1 â‡’ 2P - 2 = 0 â‡’ P = 1ï¼‰ã€‚

é€šé“æ•°ç”± 192 å˜ 128 æ˜¯é ä½¿ç”¨ 128 ä¸ªæ»¤æ³¢å™¨ã€‚

ç­” (c)ï¼š
padding = 1, stride = 1

### (d) ä¹˜æ³•æ¬¡æ•°ï¼ˆç›´æŽ¥ 3Ã—3 å·ç§¯ï¼‰

è¾“å…¥ï¼š28Ã—28Ã—192

å·ç§¯æ ¸ï¼š3Ã—3Ã—192ï¼Œå…± 128 ä¸ªæ»¤æ³¢å™¨

æ¯ä¸ªè¾“å‡ºä½ç½®ï¼š3Ã—3Ã—192 æ¬¡ä¹˜æ³•

è¾“å‡ºä½ç½®æ•°ï¼š28Ã—28Ã—128

ä¹˜æ³•æ¬¡æ•°ï¼š
(3Ã—3Ã—192)Ã—(28Ã—28Ã—128) = 1728Ã—100352 = 173,408,256

ç­” (d)ï¼š
173,408,256

### (e) å…ˆç”¨ 1Ã—1 å·ç§¯é™ç»´å† 3Ã—3 å·ç§¯

ç¬¬ä¸€æ­¥ï¼š1Ã—1 å·ç§¯ï¼Œè¾“å…¥ 192 é€šé“ â†’ 64 é€šé“ï¼Œ
æ¯ä¸ªè¾“å‡ºä½ç½®ä¹˜æ³•ï¼š1Ã—1Ã—192ï¼Œ
è¾“å‡ºä½ç½®æ•°ï¼š28Ã—28Ã—64

ä¹˜æ³•æ¬¡æ•°ï¼š192Ã—(28Ã—28Ã—64) = 192Ã—50176 = 9,633,792

ç¬¬äºŒæ­¥ï¼š3Ã—3 å·ç§¯ï¼Œè¾“å…¥ 64 é€šé“ â†’ 128 é€šé“ï¼Œ
æ¯ä¸ªè¾“å‡ºä½ç½®ä¹˜æ³•ï¼š3Ã—3Ã—64ï¼Œ
è¾“å‡ºä½ç½®æ•°ï¼š28Ã—28Ã—128

ä¹˜æ³•æ¬¡æ•°ï¼š576Ã—100352 = 57,802,752

æ€»ä¹˜æ³•æ¬¡æ•°ï¼š9,633,792 + 57,802,752 = 67,436,544

æŠ€æœ¯åç§°ï¼šç“¶é¢ˆå±‚ï¼ˆBottleneck Layerï¼‰æˆ– 1Ã—1 å·ç§¯é™ç»´ï¼ˆæ¥è‡ª GoogleNet/Inception çš„æ€æƒ³ï¼‰ã€‚

ç­” (e)ï¼š
67,436,544, Bottleneck

### (f) é‡‡ç”¨ (e) çš„æ–¹æ³•èŠ‚çœäº†å¤šå°‘æˆæœ¬

(d) ç›´æŽ¥ 3Ã—3 å·ç§¯ï¼š

173,408,256 æ¬¡ä¹˜æ³•
(e) 1Ã—1 ç“¶é¢ˆå±‚ + 3Ã—3 å·ç§¯ï¼š
67,436,544 æ¬¡ä¹˜æ³•

èŠ‚çœï¼š
173,408,256 - 67,436,544 = 105,971,712

èŠ‚çœæ¯”ä¾‹ï¼š
105,971,712 / 173,408,256 â‰ˆ 0.611ï¼ˆçº¦ 61.1%ï¼‰

ç­” (f)ï¼š
105,971,712 æ¬¡ä¹˜æ³•èŠ‚çœï¼ˆçº¦ 61%ï¼‰

### (g) ResNet ä¸­è®­ç»ƒæžæ·±ç½‘ç»œçš„æŠ€æœ¯

ResNet çš„æ ¸å¿ƒåˆ›æ–°æ˜¯æ®‹å·®è¿žæŽ¥ï¼ˆskip connection / residual connectionï¼‰ã€‚

å®ƒè®©ç½‘ç»œå±‚å­¦ä¹ æ®‹å·®æ˜ å°„ F(x) = H(x) - xï¼Œè€Œä¸æ˜¯ç›´æŽ¥å­¦ä¹  H(x)ã€‚è¿™æ ·å³ä½¿æ·±å±‚ç½‘ç»œæ’ç­‰æ˜ å°„æ˜¯æœ€ä¼˜æ—¶ï¼Œä¹Ÿå¯ä»¥è®© F(x) â†’ 0 æ¥è½»æ¾å®žçŽ°ï¼Œé¿å…äº†æ¢¯åº¦æ¶ˆå¤±å’Œç½‘ç»œé€€åŒ–é—®é¢˜ã€‚

ç­” (g)ï¼š
æ®‹å·®è¿žæŽ¥ï¼ˆskip connection / residual connectionï¼‰

### (h) GoogleNet ä¸­è®­ç»ƒæ·±åº¦ç½‘ç»œçš„æŠ€æœ¯

GoogleNet (Inception v1) çš„ä¸»è¦æŠ€æœ¯æ˜¯ Inception æ¨¡å—ï¼Œå®ƒä½¿ç”¨å¹¶è¡Œå¤šå°ºåº¦å·ç§¯ï¼ˆ1Ã—1, 3Ã—3, 5Ã—5 å’Œæ± åŒ–ï¼‰å¹¶åˆ©ç”¨ 1Ã—1 å·ç§¯é™ç»´ï¼ˆbottleneckï¼‰æ¥æŽ§åˆ¶è®¡ç®—é‡ï¼Œä½¿ç½‘ç»œæ—¢å®½åˆæ·±è€Œä¸è‡³äºŽè®¡ç®—é‡çˆ†ç‚¸ã€‚

æ­¤å¤–ï¼ŒGoogleNet è¿˜ä½¿ç”¨äº†è¾…åŠ©åˆ†ç±»å™¨ï¼ˆauxiliary classifiersï¼‰åœ¨ä¸­é—´å±‚åŠ å…¥æŸå¤±ï¼Œå¸®åŠ©æ¢¯åº¦ä¼ æ’­ç¼“è§£æ¶ˆå¤±é—®é¢˜ã€‚

é¢˜ç›®é—®â€œä»€ä¹ˆæŠ€æœ¯ä½¿æ·±åº¦ç½‘ç»œæ²¡æœ‰æ˜¾è‘—æ€§èƒ½æŸå¤±â€ï¼Œä¸»è¦ç­”æ¡ˆæ˜¯ Inception æ¨¡å—ï¼ˆå« bottleneckï¼‰ã€‚

ç­” (h)ï¼š
Inception æ¨¡å—ï¼ˆåŒ…å« 1Ã—1 å·ç§¯é™ç»´ï¼‰

![1765093189005](image/Finalwithans/1765093189005.png)
![1765093193947](image/Finalwithans/1765093193947.png)
![1765093200242](image/Finalwithans/1765093200242.png)


## Inception æž¶æž„ä¸Ž Bottleneck è¯¦è§£

### 1. Inception æ¨¡å—ï¼ˆGoogLeNetï¼‰

### æ ¸å¿ƒæ€æƒ³

ä¼ ç»Ÿå·ç§¯ç¥žç»ç½‘ç»œéœ€è¦äººå·¥é€‰æ‹©å·ç§¯æ ¸å°ºå¯¸ï¼ˆå¦‚3Ã—3ã€5Ã—5ç­‰ï¼‰ï¼Œä¸åŒå°ºå¯¸å·ç§¯æ ¸æå–çš„ç‰¹å¾ä¸åŒï¼ˆå°å°ºå¯¸æå–å±€éƒ¨ç‰¹å¾ï¼Œå¤§å°ºå¯¸æå–æ›´å…¨å±€çš„ç‰¹å¾ï¼‰ã€‚
Inceptionçš„æ ¸å¿ƒæ€æƒ³ï¼šè®©ç½‘ç»œè‡ªåŠ¨é€‰æ‹©åˆé€‚å·ç§¯æ ¸å°ºå¯¸â€”â€”åœ¨åŒä¸€å±‚å¹¶è¡Œä½¿ç”¨å¤šç§å°ºåº¦å·ç§¯æ ¸ï¼Œä½¿æ¨¡åž‹è‡ªåŠ¨å­¦ä¹ å¹¶èžåˆå¤šå°ºåº¦ç‰¹å¾ã€‚

### æœ€åˆçš„Inceptionæ¨¡å—ï¼ˆNaÃ¯ve Inceptionï¼‰

æœ€åˆè®¾è®¡æ˜¯å¹¶è¡Œä½¿ç”¨ï¼š

- 1Ã—1å·ç§¯
- 3Ã—3å·ç§¯
- 5Ã—5å·ç§¯
- 3Ã—3æœ€å¤§æ± åŒ–

ç„¶åŽå°†æ‰€æœ‰è¾“å‡ºåœ¨é€šé“ç»´åº¦æ‹¼æŽ¥ï¼ˆconcatenateï¼‰ã€‚
**é—®é¢˜**ï¼š5Ã—5å·ç§¯è®¡ç®—é‡å¾ˆå¤§ï¼Œæ± åŒ–å±‚ä¸æ”¹å˜é€šé“æ•°ï¼Œå¯¼è‡´æ€»é€šé“æ•°æ€¥å‰§å¢žåŠ ï¼Œè®¡ç®—æˆæœ¬è¿‡é«˜ã€‚

### åŠ å…¥Bottleneckçš„Inceptionæ¨¡å—

ä¸ºè§£å†³è®¡ç®—é‡é—®é¢˜ï¼ŒInception v1ï¼ˆGoogLeNetï¼‰å¼•å…¥1Ã—1å·ç§¯é™ç»´ï¼ˆBottleneckï¼‰ï¼š
**ç»“æž„**ï¼š

1. å…ˆç”¨1Ã—1å·ç§¯é™ä½Žè¾“å…¥é€šé“æ•°ï¼ˆå‡å°‘è®¡ç®—é‡ï¼‰
2. å†åº”ç”¨3Ã—3ã€5Ã—5å·ç§¯ç­‰
3. æœ€åŽå°†å„æ”¯è·¯è¾“å‡ºé€šé“æ‹¼æŽ¥

**ç¤ºä¾‹**ï¼š

- 3Ã—3å·ç§¯æ”¯è·¯ï¼šè¾“å…¥ â†’ 1Ã—1å·ç§¯é™ç»´ â†’ 3Ã—3å·ç§¯
- 5Ã—5å·ç§¯æ”¯è·¯ï¼šè¾“å…¥ â†’ 1Ã—1å·ç§¯é™ç»´ â†’ 5Ã—5å·ç§¯
- æ± åŒ–æ”¯è·¯ï¼šè¾“å…¥ â†’ æ± åŒ– â†’ 1Ã—1å·ç§¯è°ƒæ•´é€šé“æ•°

### Inceptionæ¨¡å—ç¤ºæ„å›¾

è¾“å…¥

â”‚

â”œâ”€ 1Ã—1å·ç§¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”œâ”€ 1Ã—1å·ç§¯ â†’ 3Ã—3å·ç§¯ â”€â”€â”€â”€â”€â”€â”€â”¤

â”œâ”€ 1Ã—1å·ç§¯ â†’ 5Ã—5å·ç§¯ â”€â”€â”€â”€â”€â”€â”€â”¤ é€šé“æ‹¼æŽ¥ â†’ è¾“å‡º

â”œâ”€ 3Ã—3æ± åŒ– â†’ 1Ã—1å·ç§¯ â”€â”€â”€â”€â”€â”€â”€â”˜

### Inceptionçš„ä¼˜åŠ¿

- **å¤šå°ºåº¦ç‰¹å¾æå–**ï¼šåŒæ—¶æ•èŽ·ä¸åŒæ„Ÿå—é‡Žçš„ç‰¹å¾
- **è®¡ç®—é«˜æ•ˆ**ï¼šé€šè¿‡1Ã—1å·ç§¯å…ˆé™ç»´ï¼Œå¤§å¹…å‡å°‘å‚æ•°é‡å’Œè®¡ç®—é‡
- **æ€§èƒ½æå‡**ï¼šåœ¨ImageNetç­‰æ•°æ®é›†ä¸Šè¡¨çŽ°ä¼˜å¼‚ï¼Œå‚æ•°é‡æ¯”VGGå°‘å¾ˆå¤š

---

### 2. Bottleneckï¼ˆç“¶é¢ˆå±‚ï¼‰

### ä»€ä¹ˆæ˜¯Bottleneck

Bottleneckæ˜¯æŒ‡åœ¨ç½‘ç»œä¸­å…ˆåŽ‹ç¼©é€šé“æ•°ï¼Œè¿›è¡Œå·ç§¯æ“ä½œï¼Œå†æ¢å¤é€šé“æ•°çš„ç»“æž„ã€‚ç”±äºŽé€šé“æ•°å…ˆå‡å°‘åŽå¢žåŠ ï¼Œå½¢çŠ¶ç±»ä¼¼"ç“¶é¢ˆ"ï¼Œæ•…å¾—åã€‚

### Bottleneckçš„è®¡ç®—ä¼˜åŠ¿

ä»¥å…¸åž‹åœºæ™¯ä¸ºä¾‹ï¼š

- **ç›´æŽ¥æ–¹æ¡ˆ**ï¼š3Ã—3Ã—192â†’128å·ç§¯ï¼Œè®¡ç®—é‡å¾ˆå¤§
- **Bottleneckæ–¹æ¡ˆ**ï¼š
  1. 1Ã—1Ã—192â†’64ï¼ˆå¤§å¹…é™ç»´ï¼‰
  2. 3Ã—3Ã—64â†’64ï¼ˆåœ¨ä½Žç»´ç©ºé—´å·ç§¯ï¼‰
  3. 1Ã—1Ã—64â†’128ï¼ˆæ¢å¤é€šé“æ•°ï¼‰

**è®¡ç®—é‡å¯¹æ¯”**ï¼š

- ç›´æŽ¥æ–¹æ¡ˆï¼šçº¦1.73äº¿æ¬¡ä¹˜æ³•
- Bottleneckï¼šçº¦0.67äº¿æ¬¡ä¹˜æ³•
- **èŠ‚çœçº¦61%è®¡ç®—é‡**

### Bottleneckçš„å…¶ä»–ä½œç”¨

- **é™ç»´å‡è®¡ç®—**ï¼šä¸»è¦åŠŸèƒ½
- **å¢žåŠ éžçº¿æ€§**ï¼š1Ã—1å·ç§¯åŽæŽ¥ReLUï¼Œå¢žå¼ºç½‘ç»œéžçº¿æ€§è¡¨è¾¾èƒ½åŠ›
- **ç‰¹å¾åŽ‹ç¼©ä¸Žé‡æž„**ï¼šå¯èƒ½å­¦ä¹ åˆ°æ›´ç´§å‡‘çš„ç‰¹å¾è¡¨ç¤º

---

### 3. Inceptionä¸ŽBottleneckçš„ç»“åˆ

### ååŒæ•ˆåº”

- Inceptionçš„å¤šåˆ†æ”¯å¹¶è¡Œè®¡ç®—è‹¥ä¸åŠ æŽ§åˆ¶ä¼šå¯¼è‡´è®¡ç®—é‡çˆ†ç‚¸
- Bottlenecké€šè¿‡åœ¨æ¯ä¸ªåˆ†æ”¯å…¥å£å¤„ä½¿ç”¨1Ã—1å·ç§¯é™ç»´ï¼Œä½¿Inceptionç»“æž„å˜å¾—å¯è¡Œ
- è¿™ç§ç»“åˆä½¿ç½‘ç»œæ—¢èƒ½ä¿æŒå¤šåˆ†æ”¯ï¼ˆå®½ï¼‰åˆèƒ½å¢žåŠ æ·±åº¦ï¼ŒåŒæ—¶æŽ§åˆ¶è®¡ç®—é‡

### å®žé™…åº”ç”¨

- **GoogLeNet (Inception v1)**ï¼šé¦–æ¬¡æˆåŠŸåº”ç”¨
- **Inception v2/v3**ï¼šåŠ å…¥æ‰¹é‡å½’ä¸€åŒ–ã€å·ç§¯åˆ†è§£ï¼ˆå¦‚5Ã—5â†’ä¸¤ä¸ª3Ã—3ï¼‰
- **Inception v4**ï¼šä¸Žæ®‹å·®è¿žæŽ¥ï¼ˆResidual Connectionï¼‰ç»“åˆ â†’ Inception-ResNet

---

### 4. æ·±åº¦å¯åˆ†ç¦»å·ç§¯

### Inception çš„å¯ç¤º

Inception æ¨¡å—å·²ç»æš—ç¤ºäº†ä¸€ä¸ªé‡è¦è§‚ç‚¹ï¼šç©ºé—´å·ç§¯ï¼ˆ3Ã—3ã€5Ã—5ï¼‰å’Œé€šé“äº¤äº’ï¼ˆ1Ã—1å·ç§¯ï¼‰å¯ä»¥åˆ†å¼€å¤„ç†ã€‚
åœ¨ Inception ä¸­ï¼š

1Ã—1 å·ç§¯è´Ÿè´£è·¨é€šé“çš„ä¿¡æ¯æ•´åˆ

3Ã—3ã€5Ã—5 å·ç§¯è´Ÿè´£ç©ºé—´ç‰¹å¾æå–

è¿™å®žé™…ä¸Šæ˜¯å°†é€šé“æ··åˆä¸Žç©ºé—´æ»¤æ³¢è§£è€¦çš„ç¬¬ä¸€æ­¥ã€‚

### æ·±åº¦å¯åˆ†ç¦»å·ç§¯

æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDepthwise Separable Convolutionï¼‰å°†è¿™ç§è§£è€¦æ€æƒ³æŽ¨å‘æžè‡´ï¼š

ä¸¤ä¸ªç‹¬ç«‹çš„æ­¥éª¤ï¼š

**æ·±åº¦å·ç§¯ï¼ˆDepthwise Convolutionï¼‰ï¼š**

æ¯ä¸ªè¾“å…¥é€šé“ç‹¬ç«‹è¿›è¡Œç©ºé—´å·ç§¯

åªåšç©ºé—´æ»¤æ³¢ï¼Œä¸åšé€šé“æ··åˆ

è¾“å…¥è¾“å‡ºé€šé“æ•°ç›¸åŒ

**ç‚¹å·ç§¯ï¼ˆPointwise Convolutionï¼‰ï¼š**

1Ã—1 å·ç§¯ï¼Œæ··åˆæ‰€æœ‰é€šé“çš„ä¿¡æ¯

åªåšé€šé“æ··åˆï¼Œä¸åšç©ºé—´æ»¤æ³¢

è¿™æ­£å¥½å¯¹åº”äº† Inception ä¸­"ç©ºé—´å·ç§¯æ”¯è·¯ + 1Ã—1 å·ç§¯"çš„æ€æƒ³ï¼Œä½†æ›´åŠ ç³»ç»Ÿå’Œå½»åº•ã€‚

### å…·ä½“å¯¹æ¯”

Inception ä¸­çš„ç±»ä¼¼ç»“æž„

- è€ƒè™‘ Inception çš„ä¸€ä¸ªæ”¯è·¯ï¼š1Ã—1å·ç§¯ â†’ 3Ã—3å·ç§¯
- è¿™ç±»ä¼¼äºŽï¼šå…ˆé€šé“æ··åˆ â†’ åŽç©ºé—´æ»¤æ³¢
- ä½†ä¸Žæ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„é¡ºåºç›¸å

æ·±åº¦å¯åˆ†ç¦»å·ç§¯

- æ·±åº¦å·ç§¯ â†’ é€ç‚¹å·ç§¯
- å…ˆç©ºé—´æ»¤æ³¢ â†’ åŽé€šé“æ··åˆ

è¿™ç§é¡ºåºè®¡ç®—æ•ˆçŽ‡æ›´é«˜

## Q2 2024 May ABC

![Q2](./2024MayABC/1.jpg)
![Q2](./2024MayABC/2.jpg)

## Q3 2024 Dec ABD

![Q3](./2024DecABD/3.png)

### Answer

### (a)

After applying filter F1After applying filter F2

$\begin{pmatrix} 3 & 3 & 3 & 3 & 3 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ -3 & -3 & -3 & -3 & -3 \end{pmatrix}$$\begin{pmatrix} -3 & -3 & -3 & -3 & -3 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ 3 & 3 & 3 & 3 & 3 \end{pmatrix}$

### (b)

F1Horizontal Edge Detector: (Top $0 \to 1$ and Bottom $1 \to 0$ with $\mathbf{+3}$ and $\mathbf{-3}$ response).

It detects changes in intensity along the vertical axis (a horizontal edge). It highlights the region where the patch below is brighter than the patch above it.

F2Horizontal Edge Detector (Top $0 \to 1$ and Bottom $1 \to 0$ with $\mathbf{-3}$ and $\mathbf{+3}$ response).

It detects the same horizontal edges but with the opposite polarity/sign compared to F1. F1 and F2 together provide two ways to represent the same horizontal features.

### (c)

åœ¨å°† F1 å’Œ F2 çš„ç»“æžœç›¸åŠ ä¹‹å‰ï¼Œå¸¸ç”¨ ReLU ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå› ä¸ºï¼š

è¾¹ç¼˜æ£€æµ‹ç»“æžœå¯èƒ½æœ‰æ­£æœ‰è´Ÿï¼Œä½†è´Ÿå€¼å¯èƒ½è¡¨ç¤ºåå‘è¾¹ç¼˜ï¼Œæœ‰æ—¶æˆ‘ä»¬åªå…³å¿ƒè¾¹ç¼˜å¼ºåº¦è€Œä¸å…³å¿ƒæ–¹å‘ï¼ˆæˆ–è€…ä¸¤ä¸ªæ–¹å‘éƒ½ä¿ç•™ä¸ºæ­£ï¼‰ã€‚

å¦‚æžœä½¿ç”¨ ReLUï¼Œå¯ä»¥åŽ»é™¤è´Ÿå“åº”ï¼Œåªä¿ç•™æ­£è¾¹ç¼˜ï¼Œé¿å…æ­£è´ŸæŠµæ¶ˆåœ¨ç›¸åŠ æ—¶ä¸¢å¤±ä¿¡æ¯ã€‚

å¦ä¸€ç§é€‰æ‹©æ˜¯ ç»å¯¹å€¼ï¼Œä½†æ ‡å‡† CNN ç”¨ ReLU æ›´å¸¸è§ã€‚

---

### Common Convolutional Filters

### 1. Vertical Edge Detector (e.g., Sobel or Prewitt X-axis)

This is the counterpart to the horizontal edge filter (F1/F2) you just analyzed.Vertical Edge Filter

$$
\begin{pmatrix} -1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{pmatrix}
$$

Detects vertical edges by calculating the difference in intensity between the columns. A large positive output indicates a light-to-dark transition moving from left to right, while a large negative output indicates the reverse.

### 2. Gaussian Blur Filter (Smoothing)

Gaussian Blur Filter

$$
\frac{1}{16} \begin{pmatrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{pmatrix}
$$

Smooths or blurs an image by calculating a weighted average of pixels. The weights are highest in the center (4) and decrease toward the edges (1), following a Gaussian distribution. This is used to reduce noise and detail before feature extraction, making the edge detection more robust.

### 3. Sharpening FilterSharpening Filter

$$
\begin{pmatrix} 0 & -1 & 0 \\ -1 & 5 & -1 \\ 0 & -1 & 0 \end{pmatrix}
$$

Enhances the edges and fine details of an image. It works by subtracting the blurred version of the image from the original image (or an approximation of this). The high positive weight (5) in the center emphasizes the central pixel relative to its neighbors.

### 4. $1 \times 1$ Convolution Filter (Bottleneck/Channel Mixer)

1Ã—1 Filter Concept: A single $1 \times 1 \times C_{in}$ kernel, where $C_{in}$ is the number of input channels.

This filter is primarily used for two purposes: Dimensionality Reduction (the "bottleneck" technique) and Channel Mixing. It projects the input channels into a lower-dimensional space, significantly reducing computation cost and parameter count without losing spatial resolution. It can also act as a simple channel-wise fully connected layer to learn complex relationships between feature maps.

---

## Q4 2024 Dec ABD

![Q4](./2024DecABD/5.jpg)
![Q4](./2024DecABD/6.jpg)

## Q5 2024 Dec C

![Q5](./2024DecC/5.png)

## Q6 2024 May D

![Q6](./2024MayD/2.png)
![Q6](./2024MayD/3.png)

## Q7 2023 May ABC

![Q7](./2023MayABC/3.png)
![Q7](./2023MayABC/4.png)

## Q8 2022 May 1

![Q8](./2022May1/3.png)

# Section 4 Large Language Model

## Q1 2025 May

![Q1](./2025May/5.png)
![Q1](./2025May/6.png)

## Q2 2025 May

![Q2](./2025May/7.jpg)
![Q2](./2025May/8.jpg)

### (c) self-attention åŽ dog çš„åµŒå…¥å¦‚ä½•å˜åŒ–

self-attention ä¼šè®©æ¯ä¸ªä½ç½®çš„è¾“å‡ºåµŒå…¥å˜æˆå…¶ä»–æ‰€æœ‰ä½ç½®è¾“å…¥çš„åŠ æƒç»„åˆã€‚

è¿™é‡Œ â€œdogâ€ åœ¨ä½ç½® 6ï¼Œå®ƒçš„æ–°åµŒå…¥ä¼šèžåˆ â€œBill hate #s big black dog #sâ€ ä¸­å…¶ä»–è¯çš„ä¿¡æ¯ã€‚
ä¾‹å¦‚ï¼š

â€œbigâ€ å’Œ â€œblackâ€ æ˜¯å½¢å®¹è¯ï¼Œå¯èƒ½ä¿®é¥° â€œdogâ€ï¼Œå› æ­¤ â€œdogâ€ çš„åµŒå…¥ä¼šèŽ·å¾—è¿™äº›å½¢å®¹è¯çš„ç‰¹å¾ã€‚

â€œBill hate #sâ€ å¯èƒ½è¡¨è¾¾æƒ…æ„Ÿï¼Œä¹Ÿå¯èƒ½å½±å“ â€œdogâ€ çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚

æ‰€ä»¥ â€œdogâ€ çš„åµŒå…¥ä¼šä»Žç‹¬ç«‹çš„ (-2.0, 0.5, 0.0, 0.5) å˜æˆä¸€ä¸ªåŒ…å«å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å‘é‡ï¼Œæ›´å°‘ä¾èµ–äºŽåŽŸå§‹è¯åµŒå…¥ï¼Œæ›´å¤šä¾èµ–äºŽå®ƒåœ¨å¥å­ä¸­çš„è¯­ä¹‰è§’è‰²ã€‚

---

## Q3 2024 May ABC

![Q3](./2024MayABC/3.jpg)
![Q3](./2024MayABC/4.jpg)
![Q3](./2024MayABC/5.png)

## Q4 2024 Dec ABD

![Q4](./2024DecABD/7.png)
![Q4](./2024DecABD/8.png)

### Answer by DS

### (a) (6 pts) Transformeræž¶æž„ä¼˜äºŽRNN/LSTMçš„ä¸‰ä¸ªä¸»è¦ä¼˜ç‚¹

ç­”æ¡ˆï¼š

ç›´æŽ¥çš„å…¨å±€é•¿ç¨‹äº¤äº’

RNN/LSTMæ˜¯é¡ºåºå¤„ç†ï¼Œä¿¡æ¯åœ¨åºåˆ—ä¸­é€æ­¥ä¼ é€’ï¼Œè·ç¦»è¾ƒè¿œçš„tokené—´äº¤äº’å›°éš¾ï¼Œå­˜åœ¨é•¿ç¨‹ä¾èµ–é—®é¢˜ã€‚

Transformeré€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå…è®¸åºåˆ—ä¸­ä»»æ„ä¸¤ä¸ªä½ç½®ç›´æŽ¥äº¤äº’ï¼Œæ— è®ºè·ç¦»è¿œè¿‘ï¼Œéƒ½èƒ½å»ºç«‹ç›´æŽ¥ä¾èµ–å…³ç³»ã€‚

é«˜åº¦å¹¶è¡ŒåŒ–è®¡ç®—

RNN/LSTMå¿…é¡»æŒ‰æ—¶é—´æ­¥é¡ºåºè®¡ç®—ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨çŽ°ä»£ç¡¬ä»¶çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ã€‚

Transformerçš„è‡ªæ³¨æ„åŠ›å±‚å’Œå‰é¦ˆç½‘ç»œå¯ä»¥å¯¹åºåˆ—ä¸­çš„æ‰€æœ‰å…ƒç´ åŒæ—¶è®¡ç®—ï¼Œæžå¤§æå‡äº†è®­ç»ƒå’ŒæŽ¨ç†æ•ˆçŽ‡ã€‚

çµæ´»ä¸”æ›´å¤§çš„åµŒå…¥ç»´åº¦

RNN/LSTMå—é™äºŽè®¡ç®—æ•ˆçŽ‡ï¼Œé€šå¸¸ä½¿ç”¨ç›¸å¯¹è¾ƒå°çš„éšè—çŠ¶æ€ç»´åº¦ã€‚

Transformerçš„å¹¶è¡Œæž¶æž„ä½¿å…¶èƒ½å¤Ÿæ”¯æŒæ›´å¤§çš„åµŒå…¥ç»´åº¦å’Œéšè—å±‚ç»´åº¦ï¼Œä»Žè€Œå­¦ä¹ æ›´ä¸°å¯Œã€æ›´å¤æ‚çš„è¡¨ç¤ºï¼Œè€Œä¸ä¼šæ˜¾è‘—å¢žåŠ è®­ç»ƒæ—¶é—´ã€‚

![Q4](./2024DecABD/9.png)

### (b) (4 pts) Transformerå¦‚ä½•è§£å†³(a)ä¸­æå‡ºçš„é—®é¢˜ï¼Ÿ

ç­”æ¡ˆï¼š

é’ˆå¯¹é—®é¢˜1ï¼ˆå…¨å±€ä¾èµ–æ€§ï¼‰ï¼šé€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ è§£å†³ã€‚åœ¨è®¡ç®—æŸä¸ªä½ç½®çš„è¡¨ç¤ºæ—¶ï¼Œå®ƒä¼šç›´æŽ¥å…³æ³¨å¹¶èšåˆåºåˆ—ä¸­æ‰€æœ‰å…¶ä»–ä½ç½®çš„ä¿¡æ¯ï¼Œä»Žè€Œç«‹å³å»ºç«‹å…¨å±€ä¾èµ–å…³ç³»ï¼Œæ— éœ€åƒRNNé‚£æ ·é€šè¿‡å¤šä¸ªæ—¶é—´æ­¥ä¼ é€’ã€‚

é’ˆå¯¹é—®é¢˜2ï¼ˆå¹¶è¡ŒåŒ–ï¼‰ï¼šé€šè¿‡æ‘’å¼ƒå¾ªçŽ¯ç»“æž„å¹¶å®Œå…¨ä¾èµ–å‰é¦ˆç½‘ç»œå’ŒçŸ©é˜µä¹˜æ³• è§£å†³ã€‚æ•´ä¸ªè¾“å…¥åºåˆ—è¢«ä½œä¸ºä¸€ä¸ªæ•´ä½“è¾“å…¥æ¨¡åž‹ï¼Œæ‰€æœ‰æ³¨æ„åŠ›æƒé‡å’Œå±‚å†…å˜æ¢éƒ½å¯ä»¥é€šè¿‡é«˜æ•ˆçš„çŸ©é˜µè¿ç®—å¹¶è¡Œå®Œæˆã€‚

### (c) (6 pts) æ³¨æ„åŠ›æœºåˆ¶ä¸­K, Q, Vçš„è§£é‡Š

(i) è¶…å¸‚æ‰¾ç‰©å“åœºæ™¯ï¼š

æŸ¥è¯¢ï¼šæ¯ä¸ªè´­ç‰©è€…å¿ƒä¸­çš„ç‰©å“åç§°ã€‚å®ƒä»£è¡¨äº†â€œæˆ‘éœ€è¦ä»€ä¹ˆâ€ã€‚

é”®ï¼šè¶…å¸‚è´§æž¶ä¸Šæ¯ä¸ªå•†å“çš„æ ‡ç­¾åç§°ã€‚å®ƒä»£è¡¨äº†â€œæˆ‘æ˜¯ä»€ä¹ˆâ€ã€‚

å€¼ï¼šè´§æž¶ä¸Šçš„å•†å“æœ¬èº«ã€‚ä¸€æ—¦é€šè¿‡åŒ¹é…Qå’ŒKæ‰¾åˆ°äº†æ­£ç¡®çš„ç‰©å“ï¼Œä½ æœ€ç»ˆæ‹¿å–çš„å°±æ˜¯è¿™ä¸ªVã€‚

è¿‡ç¨‹ï¼šè´­ç‰©è€…ï¼ˆQï¼‰å°†è‡ªå·±çš„éœ€æ±‚ä¸Žè´§æž¶ä¸Šæ‰€æœ‰å•†å“çš„æ ‡ç­¾ï¼ˆKï¼‰è¿›è¡Œæ¯”å¯¹ã€‚æ‰¾åˆ°åŒ¹é…åº¦æœ€é«˜çš„æ ‡ç­¾åŽï¼Œå°±å–èµ°è¯¥æ ‡ç­¾å¯¹åº”çš„å®žé™…å•†å“ï¼ˆVï¼‰ã€‚

(ii) åˆ†é…æœ€è¿‘Uberè½¦è¾†åœºæ™¯ï¼š

æŸ¥è¯¢ï¼šä¹˜å®¢çš„ä¹˜è½¦è¯·æ±‚å’Œä½ç½®ã€‚å®ƒä»£è¡¨äº†â€œæˆ‘éœ€è¦ä¸€è¾†è½¦åœ¨è¿™é‡Œâ€ã€‚

é”®ï¼šæ‰€æœ‰å¯ç”¨Uberè½¦è¾†çš„ä½ç½®å’ŒçŠ¶æ€ã€‚å®ƒä»£è¡¨äº†â€œæˆ‘æ˜¯ä¸€è¾†å¯ç”¨çš„è½¦ï¼Œæˆ‘åœ¨è¿™é‡Œâ€ã€‚

å€¼ï¼šå¯ç”¨çš„Uberè½¦è¾†æœ¬èº«ã€‚å®ƒæ˜¯æœ€ç»ˆè¢«åˆ†é…ç»™ä¹˜å®¢çš„å®žä½“ã€‚

è¿‡ç¨‹ï¼šç³»ç»Ÿå°†ä¹˜å®¢çš„è¯·æ±‚ï¼ˆQï¼‰ä¸Žæ‰€æœ‰å¯ç”¨è½¦è¾†çš„ä¿¡æ¯ï¼ˆKï¼‰è¿›è¡ŒåŒ¹é…ï¼Œè®¡ç®—å‡ºä¸€ä¸ªâ€œè·ç¦»åˆ†æ•°â€ã€‚é€‰æ‹©åˆ†æ•°æœ€é«˜ï¼ˆå³æœ€è¿‘/æœ€åˆé€‚ï¼‰çš„è½¦è¾†ï¼ˆVï¼‰åˆ†é…ç»™è¯¥ä¹˜å®¢ã€‚

### (d) (3 pts) ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›æœºåˆ¶çš„å®žçŽ°åŠåŽŸå› 

ç­”æ¡ˆï¼š

å®žçŽ°æ–¹å¼ï¼š

æŸ¥è¯¢ æ¥è‡ªè§£ç å™¨çš„å‰ä¸€å±‚è¾“å‡ºã€‚

é”®å’Œå€¼ å‡æ¥è‡ªç¼–ç å™¨çš„æœ€ç»ˆè¾“å‡ºã€‚

åŽŸå› ï¼š
è¿™ç§å®žçŽ°å…è®¸è§£ç å™¨åœ¨ç”Ÿæˆæ¯ä¸€ä¸ªç›®æ ‡è¯­è¨€è¯æ±‡æ—¶ï¼Œæœ‰é€‰æ‹©åœ°å…³æ³¨è¾“å…¥åºåˆ—ä¸­æœ€ç›¸å…³çš„éƒ¨åˆ†ã€‚å®ƒè®©è§£ç å™¨èƒ½å¤Ÿâ€œæŸ¥é˜…â€å®Œæ•´çš„ç¼–ç æºä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–è§£ç å™¨è‡ªèº«çš„éšè—çŠ¶æ€ã€‚è¿™æ¨¡ä»¿äº†äººç±»åœ¨ç¿»è¯‘æ—¶çš„è¡Œä¸ºï¼šåœ¨å†™å‡ºä¸‹ä¸€ä¸ªè¯ä¹‹å‰ï¼Œä¼šå›žçœ‹æ•´ä¸ªæºå¥å­çš„æ„æ€ä»¥ç¡®å®šæœ€ä½³è¡¨è¾¾ã€‚

### (e) (4 pts) Transformeræž¶æž„çš„ç¼ºç‚¹

ç­”æ¡ˆï¼š

è®¡ç®—å¤æ‚åº¦é«˜ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—å¤æ‚åº¦ä¸Žåºåˆ—é•¿åº¦çš„å¹³æ–¹æˆæ­£æ¯”ï¼ˆO(nÂ²)ï¼‰ï¼Œè¿™ä½¿å¾—å¤„ç†éžå¸¸é•¿çš„æ–‡æ¡£æˆ–é«˜åˆ†è¾¨çŽ‡å›¾åƒå˜å¾—éžå¸¸æ˜‚è´µå’Œå›°éš¾ã€‚

ä½ç½®ä¿¡æ¯éœ€è¦æ˜¾å¼æ³¨å…¥ï¼šç”±äºŽè‡ªæ³¨æ„åŠ›æœ¬èº«æ˜¯ç½®æ¢ä¸å˜çš„ï¼ˆä¸å…³å¿ƒé¡ºåºï¼‰ï¼Œæ¨¡åž‹å¿…é¡»ä¾èµ–é¢å¤–æ·»åŠ çš„ä½ç½®ç¼–ç æ¥ç†è§£åºåˆ—ä¸­å…ƒç´ çš„é¡ºåºï¼Œè¿™ä¸å¦‚RNN/LSTMå†…ç”Ÿçš„é¡ºåºå¤„ç†æœºåˆ¶ç›´æŽ¥ã€‚

å·¨å¤§çš„å†…å­˜å’Œè®¡ç®—èµ„æºæ¶ˆè€—ï¼šåºžå¤§çš„æ¨¡åž‹å‚æ•°é‡ã€å¤§çš„æ¿€æ´»å€¼å’Œæ³¨æ„åŠ›çŸ©é˜µéœ€è¦å¤§é‡çš„GPUå†…å­˜ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™çŽ¯å¢ƒä¸­çš„åº”ç”¨ã€‚

ç¼ºä¹å½’çº³åç½®ï¼šè™½ç„¶å…¶é€šç”¨æ€§æ˜¯ä¸ªä¼˜ç‚¹ï¼Œä½†è¿™ä¹Ÿæ„å‘³ç€å®ƒéœ€è¦æ¯”RNNæ›´å¤šçš„æ•°æ®æ¥å­¦ä¹ ä¸€äº›å›ºæœ‰çš„åºåˆ—ç‰¹æ€§ï¼ˆå¦‚å±€éƒ¨æ€§ï¼‰ï¼Œå¯èƒ½å¯¼è‡´åœ¨å°åž‹æ•°æ®é›†ä¸Šè¿‡æ‹Ÿåˆã€‚

---

### Answer by GPT

### (a) (6 pts) Three main advantages that make Transformer superior to RNN/LSTM

Advantages:

Parallel computation â€“

Transformers process all tokens simultaneously instead of sequentially (no recurrence).

â†’ Much faster training, especially on GPUs.

Long-range dependency modeling â€“

Self-attention lets every token directly attend to every other token.

â†’ Captures global context better than RNNs/LSTMs, which suffer from vanishing gradients over long sequences.

Fixed embedding dimension (independent of sequence length) â€“

Word embeddings and positional encodings have a constant size.

â†’ Enables stable representations regardless of input length.

### (b) (4 pts) How Transformer solves RNN/LSTM problems

Removes sequential dependency: self-attention computes relationships among tokens in parallel, avoiding step-by-step recurrence.

Handles long context: attention weights connect distant words directly (no gradient decay through time).

Stable embeddings: constant-dimension positional + word embeddings replace hidden states whose size and quality degrade over long sequences.

### (c) (6 pts) Interpretation of K, Q, V (Keys, Queries, Values)

Scenario	Analogy	Explanation
(i) Supermarket example	- Each person = a Query (Q) (they are â€œaskingâ€ for something).

- Each shelf label = a Key (K) (what items are available).
- Each item on the shelf = a Value (V) (the actual content retrieved).	The person (Q) scans all shelves (K) to find the best match and then picks the corresponding item (V).
  (ii) Uber example	- Each passenger request = a Query (Q).
- Each carâ€™s location = a Key (K).
- Each carâ€™s details (driver info, ETA, etc.) = a Value (V).	The system computes attention (similarity) between passenger Q and car K to assign the closest car (retrieve its V).

### (d) (3 pts) Encoder-decoder attention mechanism

In encoderâ€“decoder attention, the decoderâ€™s queries (Q) attend to the encoderâ€™s output keys (K) and values (V).

This lets each decoder token focus on the most relevant encoder tokens when generating output (e.g., aligning target words with source words in translation).

Reason: enables information flow from the input sentence (encoder) to the output sentence (decoder) for accurate sequence generation.

### (e) (4 pts) Shortcomings of Transformer architecture

High computational and memory cost:

Self-attention scales as O(nÂ²) with sequence length.

Requires large datasets to train effectively.

Limited inductive bias for sequential order:

Positional encoding is less intuitive than recurrence for time-dependent data.

Interpretability and efficiency issues:

Many attention heads are redundant; not easily interpretable.

## Q5 2025 May

![Q5](./2025May/12.png)

### Answer

### (a) Transformer ä¸­çš„ Masking

åœ¨ Transformer ä¸­ï¼ŒMasking ä¸»è¦ç”¨äºŽ Decoder çš„è‡ªæ³¨æ„åŠ›å±‚ï¼Œç›®çš„æ˜¯é˜²æ­¢åœ¨è®­ç»ƒæ—¶â€œå·çœ‹â€æœªæ¥çš„ä¿¡æ¯ã€‚

åœ¨è‡ªå›žå½’ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚æœºå™¨ç¿»è¯‘ï¼‰ä¸­ï¼ŒDecoder åœ¨é¢„æµ‹ç¬¬ t ä¸ªä½ç½®æ—¶ï¼Œåªèƒ½ä½¿ç”¨å‰ t ä¸ªä½ç½®çš„ä¿¡æ¯ã€‚

é€šè¿‡ æ³¨æ„åŠ›æŽ©ç ï¼ˆä¸€ä¸ªä¸‹ä¸‰è§’ä¸º 0ã€ä¸Šä¸‰è§’ä¸º -inf çš„çŸ©é˜µï¼‰ï¼Œå°†æœªæ¥ä½ç½®çš„æ³¨æ„åŠ›æƒé‡è®¾ä¸º 0ï¼Œç¡®ä¿æ¨¡åž‹åªèƒ½å…³æ³¨å·²ç”Ÿæˆçš„éƒ¨åˆ†ã€‚

è¿™æ ·ï¼Œè®­ç»ƒæ—¶å³ä½¿ä¸€æ¬¡æ€§è¾“å…¥æ•´ä¸ªç›®æ ‡åºåˆ—ï¼Œä¹Ÿä¸ä¼šä¿¡æ¯æ³„æ¼ã€‚

### (b) BERT ä¸­çš„ Masking

BERT ä½¿ç”¨ Masking ä½œä¸º é¢„è®­ç»ƒä»»åŠ¡ï¼ˆMasked Language Model, MLMï¼‰ã€‚

åœ¨è¾“å…¥åºåˆ—ä¸­ï¼Œéšæœºé®ç›–ï¼ˆMaskï¼‰ä¸€éƒ¨åˆ† tokenï¼ˆå¦‚ 15%ï¼‰ã€‚

æ¨¡åž‹çš„ä»»åŠ¡æ˜¯åŸºäºŽä¸Šä¸‹æ–‡ï¼ˆåŒå‘ä¿¡æ¯ï¼‰é¢„æµ‹è¢«é®ç›–çš„åŽŸå§‹ tokenã€‚

è¿™ä½¿å¾— BERT èƒ½å­¦ä¹ æ·±å±‚çš„åŒå‘è¯­è¨€è¡¨å¾ï¼Œè€Œä¸æ˜¯åƒä»Žå·¦åˆ°å³çš„è¯­è¨€æ¨¡åž‹é‚£æ ·åªçœ‹åˆ°ä¸Šæ–‡ã€‚

æ³¨æ„ï¼šBERT åœ¨é¢„è®­ç»ƒæ—¶ä½¿ç”¨ [MASK] ç¬¦å·ï¼Œä½†åœ¨å¾®è°ƒæ—¶æ‰€æœ‰è¾“å…¥ token éƒ½æ˜¯çœŸå®žè¯ï¼Œä¸å­˜åœ¨ [MASK]ï¼Œè¿™å¸¦æ¥ä¸€å®šçš„é¢„è®­ç»ƒ-å¾®è°ƒå·®å¼‚ï¼ŒBERT é€šè¿‡æ›¿æ¢éƒ¨åˆ†é®ç›–è¯ä¸ºéšæœºè¯æˆ–åŽŸè¯æ¥ç¼“è§£ã€‚

### (c) è§†è§‰ä¸­çš„é®æŒ¡æ•æ„Ÿæ€§

é®æŒ¡æ•æ„Ÿæ€§æ˜¯ä¸€ç§ å¯è§£é‡Šæ€§/åˆ†æžæŠ€æœ¯ï¼Œç”¨äºŽç†è§£ CNN ç­‰æ¨¡åž‹ä¾èµ–å›¾åƒçš„å“ªäº›åŒºåŸŸè¿›è¡Œé¢„æµ‹ã€‚

æ–¹æ³•ï¼šåœ¨è¾“å…¥å›¾åƒä¸Šç”¨ä¸€ä¸ªç°è‰²æ–¹å—æˆ–æ¨¡ç³ŠåŒºåŸŸé®æŒ¡ä¸€å°å—åŒºåŸŸï¼Œç„¶åŽè§‚å¯Ÿæ¨¡åž‹é¢„æµ‹æ¦‚çŽ‡çš„å˜åŒ–ã€‚

é€šè¿‡ç³»ç»Ÿæ€§åœ°æ»‘åŠ¨é®æŒ¡å—å¹¶è®°å½•é¢„æµ‹å¾—åˆ†ï¼Œå¯ä»¥ç”Ÿæˆä¸€ä¸ªâ€œæ•æ„Ÿæ€§å›¾â€ï¼šå¦‚æžœé®æŒ¡æŸåŒºåŸŸå¯¼è‡´é¢„æµ‹æ¦‚çŽ‡å¤§å¹…ä¸‹é™ï¼Œè¯´æ˜Žè¯¥åŒºåŸŸå¯¹æ¨¡åž‹å†³ç­–å¾ˆé‡è¦ã€‚

è¿™ç±»ä¼¼äºŽ NLP ä¸­é®ç›–ä¸€ä¸ªè¯çœ‹å¥å­æ¦‚çŽ‡çš„å˜åŒ–ï¼Œä½†åœ¨è§†è§‰ä¸­ç”¨äºŽå®šä½å…³é”®å›¾åƒåŒºåŸŸã€‚

---

# Section 5 Model Size & Quantization

## Q1 2025 May

![Q1](./2025May/3.png)

## Q2 2025 May

![Q2](./2025May/4.png)

# Section 6 Generative Adversarial Networks

## Q1 2025 May

![Q1](./2025May/11.png)

### Answer

### (a)

GAN çš„åŽŸå§‹è®ºæ–‡ä¸­ï¼Œç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„ä¼˜åŒ–ç›®æ ‡å¯ä»¥å†™æˆ äºŒå…ƒäº¤å‰ç†µï¼ˆBinary cross-entropyï¼‰ çš„å½¢å¼ï¼Œä¹Ÿå°±æ˜¯ Binary logistic lossã€‚

A äº¤å‰ç†µæŸå¤±ï¼ˆCross-entropy lossï¼‰ä¸€èˆ¬æŒ‡å¤šåˆ†ç±»äº¤å‰ç†µï¼Œè™½ç„¶äºŒå…ƒäº¤å‰ç†µæ˜¯å®ƒçš„ç‰¹ä¾‹ï¼Œä½†é€šå¸¸ä¸ç›´æŽ¥è¿™ä¹ˆè¯´ã€‚

B å‡æ–¹è¯¯å·®æŸå¤±ï¼ˆMSEï¼‰ä¸æ˜¯ GAN åŽŸå§‹ç‰ˆæœ¬å¸¸ç”¨çš„ï¼Œå°½ç®¡æœ‰äº›å˜ä½“ï¼ˆå¦‚ LSGANï¼‰ç”¨äº† MSEã€‚

C äºŒå…ƒé€»è¾‘æŸå¤±ï¼ˆBinary logistic lossï¼‰å°±æ˜¯äºŒå…ƒäº¤å‰ç†µï¼Œè¿™æ˜¯åŽŸå§‹ GAN ç”¨çš„ã€‚

D Softmax æŸå¤±ç”¨äºŽå¤šåˆ†ç±»ï¼Œä¸æ˜¯ GAN åˆ¤åˆ«å™¨äºŒåˆ†ç±»çš„æ ‡é…ã€‚

å› æ­¤ç­”æ¡ˆæ˜¯ Cã€‚

### (b)

**DeepSeek**

A ç”Ÿæˆå™¨çš„è¾“å…¥ä¸€èˆ¬æ˜¯éšæœºå™ªzï¼Œä¸åŒçš„zäº§ç”Ÿä¸åŒæ ·æœ¬ï¼Œå› æ­¤ä¸Žæ ·æœ¬å¤šæ ·æ€§æœ‰å…³ã€‚

B è°ƒæ•´ç”Ÿæˆå™¨çš„æƒé‡å’Œåå·®ä¼šå½±å“ç”Ÿæˆæ ·æœ¬çš„åˆ†å¸ƒï¼Œå› æ­¤ä¹Ÿå½±å“å¤šæ ·æ€§ã€‚

C æ¨¡å¼å´©æºƒï¼ˆMode collapseï¼‰æ˜¯ GAN è®­ç»ƒå¤±è´¥çš„ä¸€ç§æƒ…å†µï¼Œå¯¼è‡´ç”Ÿæˆæ ·æœ¬ç¼ºä¹å¤šæ ·æ€§ï¼Œå› æ­¤ä¸Žå¤šæ ·æ€§æœ‰å…³ï¼ˆè´Ÿé¢ç›¸å…³ï¼‰ã€‚

D æ¡ä»¶ GANï¼ˆConditional GANï¼‰é€šè¿‡é™„åŠ æ¡ä»¶ä¿¡æ¯æŽ§åˆ¶ç”Ÿæˆæ ·æœ¬çš„ç±»åˆ«ï¼Œå¯ä»¥å¢žåŠ å¤šæ ·æ€§ï¼ˆä¾‹å¦‚æŒ‰ç±»åˆ«ç”Ÿæˆä¸åŒæ ·æœ¬ï¼‰ã€‚

å› æ­¤ Aã€Bã€Cã€D éƒ½ç›¸å…³ã€‚

**Gemini**

Sample variations refer to the ability of the GAN to produce diverse outputs.

A. Input in the generator component of a GAN: The generator's input is a random noise vector ($z$), which is the primary source of variation in the generated output. Different noise vectors lead to different generated images.

B. Adjusting the weights and biases of the generator: This relates to training the generator to learn the data distribution, which is how it enables variation, but the input noise is the immediate cause of variation for a trained generator.

C. Mode collapse in GANs: This is a problem where the generator fails to produce diverse outputs (i.e., it only generates a small subset of the true data distribution's "modes"). It is fundamentally related to sample variations, but as a failure condition. If the question implies things that enable or govern variation, A is better. If it asks what involves variation, C is relevant. Given the options, A and D are direct enablers.

D. Conditional GAN: By conditioning the GAN on external information (e.g., a class label), you explicitly control and vary the type of sample generated, leading to planned variations.

Selected Answer(s): A. Input in the generator component of a GAN and D. Conditional GAN.

**GPT**
A: The random noise vector (z) fed into the generator is the source of sample variation.

D: Conditional GANs (cGANs) control variation by conditioning on labels or attributes (e.g., class, text).

C: Mode collapse reduces variation â€” itâ€™s a problem related to variation (lack thereof).

B: Adjusting weights/biases affects learning but not the source of variation directly.

So the best set: A, C, D

### (c)

**DeepSeek**

* A é”™ï¼Œå› ä¸ºè®­ç»ƒæ—¶æ˜¯äº¤æ›¿è®­ç»ƒç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œä¸æ˜¯åªè®­ç»ƒç”Ÿæˆå™¨ã€‚
* B å¯¹ï¼Œè®­ç»ƒæ—¶æ˜¯äº¤æ›¿è®­ç»ƒï¼ˆeither â€¦ or â€¦ï¼‰ã€‚
* C é”™ï¼Œç›®æ ‡ä¸æ˜¯è®©åˆ¤åˆ«å™¨å‡†ç¡®çŽ‡å›ºå®šåœ¨ 0.5ï¼Œè€Œæ˜¯å¸Œæœ›ç”Ÿæˆæ ·æœ¬åˆ†å¸ƒä¸ŽçœŸå®žåˆ†å¸ƒä¸å¯åˆ†æ—¶ï¼Œåˆ¤åˆ«å™¨è‡ªç„¶è¶‹è¿‘ 0.5ï¼Œä½†è®­ç»ƒè¿‡ç¨‹ä¸æ˜¯ç›´æŽ¥ä¸ºæ­¤ä¼˜åŒ–ã€‚
* D å¯¹ï¼Œè®­ç»ƒç”Ÿæˆå™¨æ—¶å¸Œæœ›åˆ¤åˆ«å™¨å¯¹ç”Ÿæˆæ ·æœ¬è¾“å‡º 1ï¼ˆå³éª—è¿‡åˆ¤åˆ«å™¨ï¼‰ï¼Œè®­ç»ƒåˆ¤åˆ«å™¨æ—¶å¸Œæœ›çœŸå®žæ ·æœ¬æ ‡ 1ã€ç”Ÿæˆæ ·æœ¬æ ‡ 0ã€‚

å› æ­¤ç­”æ¡ˆæ˜¯  **B å’Œ D** ã€‚

**Gemini&GPT**

The GAN training is an iterative two-step process:

Train the Discriminator ($D$):

Goal: Maximize $\log D(x)$ for real samples $x$ (score close to 1).

Goal: Maximize $\log(1 - D(G(z)))$ for fake samples $G(z)$ (score close to 0).

Train the Generator ($G$):

Goal: Minimize $\log(1 - D(G(z)))$, which is equivalent to maximizing $\log D(G(z))$ for the generated samples (score close to 1, to fool the discriminator).

When a sample is generated by $G(z)$:

The discriminator is trained to score it 0 (or low) because it's fake.

The generator is trained to get the discriminator to score it 1 (or high) because its goal is to fool the discriminator.

Selected Answer(s): D. The generator is trained for score 1 and the discriminator for score 0 (when processing a generated/fake sample).

---

## Q2 2024 May ABC

![Q2](./2024MayABC/8.png)

### Answer

### (a)

A GAN consists of two competing neural networks: the Generator ($G$) and the Discriminator ($D$). They are trained simultaneously in an adversarial process.

![Q2](./2024MayABC/10.png)
![Q2](./2024MayABC/9.png)

### (b)

Mode collapse â€“ the generator produces limited or identical outputs (poor diversity).(PPT)

Non-convergence / instability â€“ adversarial training may oscillate instead of converging. (PPT)

Vanishing gradients â€“ if the discriminator becomes too strong, the generator receives almost no gradient signal.

Sensitive hyperparameters â€“ training depends heavily on learning rates, architectures, and batch normalization.

Evaluation difficulty â€“ itâ€™s hard to quantify sample quality objectively.

Distorted figures (PPT ä¸ç®—è®­ç»ƒä¸­çš„é—®é¢˜ï¼Ÿ)

### (c)

The standard GAN uses Binary Cross-Entropy (BCE) loss. When the Discriminator ($D$) outputs a score of $\mathbf{0.2}$ on a generated instance $G(z)$, the training is conducted in two steps:

1. Training the Discriminator ($D$)  The Discriminator's goal is to correctly classify the generated sample as Fake (target label $y=0$).
   Discriminator Loss on Fake Sample:

   $$
   L_D(\text{fake}) = -\log(1 - D(G(z)))
   $$

   Loss Value:

   $$
   L_D(\text{fake}) = -\log(1 - 0.2) = -\log(0.8) \approx \mathbf{0.223}
   $$

   Training Action: The discriminator's weights are adjusted to reduce this loss, which pushes its output $D(G(z))$ closer to 0.
2. Training the Generator ($G$)  The Generator's goal is to make the Discriminator classify the generated sample as Real (target label $y=1$) to fool it.
   Generator Loss (Non-saturating):

   $$
   L_G = -\log(D(G(z)))
   $$

   Loss Value:

   $$
   L_G = -\log(0.2) \approx \mathbf{1.609}
   $$

   Training Action: The generator's weights are adjusted to reduce this loss, which pushes the Discriminator's output $D(G(z))$ closer to 1.

Summary: The Discriminator gets a relatively small gradient and updates to be slightly better at classifying the sample as fake. The Generator gets a large gradient and updates aggressively to make the Discriminator score the sample higher.

### (d)

A Conditional Generative Adversarial Network (cGAN) using Convolutional Neural Networks (CNNs).

Reason:

Input: grayscale (black-and-white) image.

Condition: this grayscale image acts as the conditional input to guide generation.

Generator (CNN-based, often U-Net) learns to output corresponding color channels.

Discriminator checks whether the colored image is realistic given the grayscale input.
â†’ CNNs handle spatial features effectively, and conditioning ensures consistent colorization.

| Concept           | What It Is                                                                                                                                                                                       | Level                                         |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------- |
| **U-Net**   | A**neural network architecture** â€” an *encoderâ€“decoder* with skip connections, originally designed for biomedical image segmentation (Ronneberger et al., 2015).                       | **Architecture (building block)**       |
| **Pix2Pix** | A**complete framework / model** â€” a *conditional GAN* (cGAN) for image-to-image translation that **uses a U-Net as its generator** and a **PatchGAN as its discriminator**. | **Model framework (uses U-Net inside)** |

![Q2](./2024MayABC/11.png)
![Q2](./2024MayABC/12.png)

### (e)

å›¾çµæµ‹è¯•ï¼šåˆ¤æ–­è€…ä¸Žä¸€ä¸ªäººå’Œä¸€ä¸ªæœºå™¨é€šè¿‡æ–‡æœ¬äº¤äº’ï¼Œå¦‚æžœåˆ¤æ–­è€…æ— æ³•åŒºåˆ†æœºå™¨å’Œäººï¼Œåˆ™æœºå™¨é€šè¿‡æµ‹è¯•ã€‚

GAN ä¸­çš„ç±»æ¯”ï¼š

åˆ¤åˆ«å™¨ â†” åˆ¤æ–­è€…

ç”Ÿæˆå™¨ â†” æœºå™¨

çœŸå®žæ•°æ® â†” äººçš„å›žç­”

ç”Ÿæˆæ•°æ® â†” æœºå™¨çš„å›žç­”

ç›®æ ‡éƒ½æ˜¯è®©æœºå™¨ï¼ˆç”Ÿæˆå™¨ï¼‰äº§ç”Ÿä¸ŽçœŸäººï¼ˆçœŸå®žæ•°æ®ï¼‰æ— æ³•åŒºåˆ†çš„ç»“æžœï¼Œä»Žè€Œéª—è¿‡åˆ¤æ–­è€…ï¼ˆåˆ¤åˆ«å™¨ï¼‰ã€‚

The Turing Test evaluates whether a machine can generate outputs indistinguishable from a humanâ€™s.

Similarly, in a GAN, the discriminator acts like the human judge, and the generator acts like the machine trying to fool it.

The goal: the generator produces data so realistic that the discriminator canâ€™t tell it apart from real data (ideally 50/50 confusion).
â†’ Thus, GAN training is an automated version of the Turing test in the data domain.

## Q3 2022 May 2

![Q3](./2022May2/4.png)
![Q3](./2022May2/5.png)
![Q3](./2022May2/6.png)

### Answer

### (a) Discriminator evaluates real data and gives answer 0.4.

The Discriminator ($D$) is trained to classify real data ($\mathbf{x}$) with a target label of 1 (or high probability). The standard loss function is Binary Cross-Entropy (BCE).

Which part(s) of GAN can be trained?Only the Discriminator ($D$) is trained. The Generator ($G$) is not involved in processing real data.

What is the loss value?The Discriminator's loss on real data is $L_D(\text{real}) = -\log(D(\mathbf{x}))$.With $D(\mathbf{x}) = 0.4$:

$$
L_D(\text{real}) = -\log(0.4) \approx \mathbf{0.916}
$$

Since the score of 0.4 is far from the target of 1, this loss is relatively high, and the Discriminator's weights will be adjusted to increase its score for real data towards 1.

### (b) Discriminator evaluates generated data and gives answer 0.7.

When processing generated data $G(\mathbf{z})$, both the Discriminator and the Generator are involved, but they have opposite objectives.

1. Training the Discriminator ($D$)Target Label:

The Discriminator aims to classify the generated sample as Fake (target label 0).

Which part(s) of GAN can be trained?The Discriminator ($D$) is trained.
Loss Value:$L_D(\text{fake}) = -\log(1 - D(G(\mathbf{z})))$.

With $D(G(\mathbf{z})) = 0.7$:

$$
L_D(\text{fake}) = -\log(1 - 0.7) = -\log(0.3) \approx \mathbf{1.204}
$$

This is a high loss because $0.7$ is closer to $1$ than to the target of $0$. The Discriminator's weights will be adjusted to decrease its score for the generated data towards 0.

2. Training the Generator ($G$)

Target Label: The Generator aims to fool the Discriminator, making it output 1 (Real). The common non-saturating loss is used.Which part(s) of GAN can be trained?The Generator ($G$) is trained.Loss Value:$L_G = -\log(D(G(\mathbf{z})))$.

With $D(G(\mathbf{z})) = 0.7$:

$$
L_G = -\log(0.7) \approx \mathbf{0.357}
$$

This is a relatively low loss for the Generator, as the score of $0.7$ is already quite close to its target of $1$. The Generator's weights will be adjusted to make the output score slightly higher than 0.7.

### (c) Can both parts of the network be trained simultaneously by backpropagation? Justify your answer.

No, both parts of the network (Generator $G$ and Discriminator $D$) are typically not trained simultaneously in a single backpropagation pass, especially in the standard GAN formulation.

Justification:

Adversarial Objectives: $G$ and $D$ have conflicting objectives. $D$ tries to maximize $\log D(\mathbf{x}) + \log(1 - D(G(\mathbf{z})))$, while $G$ tries to minimize $\log(1 - D(G(\mathbf{z})))$ (or maximize $\log D(G(\mathbf{z}))$). Training them simultaneously on a single combined loss would lead to an unstable gradient with undefined behavior.

Separate Forward Passes: The typical training procedure is done in alternating steps:Step 1: Run a forward pass and backpropagate the loss to update only $D$'s weights, keeping $G$'s weights fixed.Step 2: Run a forward pass and backpropagate the loss to update only $G$'s weights, keeping $D$'s weights fixed.

Need for Frozen Network: When training $G$, the goal is to make $D$ score the fake data high. If $D$'s weights were also changing during this step, the target would be constantly moving, making the optimization impossible. Therefore, for the $G$ update, the $D$ network is frozen.

### (d) L1 Loss calculation

What is the formula for L1?

The L1 loss (also known as the Mean Absolute Error (MAE)) measures the average magnitude of the errors between the ground truth and the generated result. For two matrices (or vectors) $\mathbf{T}$ (ground truth) and $\mathbf{G}$ (generated result), the L1 loss is:

$$
L_1(\mathbf{T}, \mathbf{G}) = \frac{1}{N} \sum_{i=1}^{N} |\mathbf{T}_i - \mathbf{G}_i|
$$

Where $N$ is the total number of elements, and $\mathbf{T}_i$ and $\mathbf{G}_i$ are the $i$-th elements of the ground truth and generated result, respectively.

What is the L1 loss for the above two matrices?

The ground truth $\mathbf{T}_1$ and generated result $\mathbf{G}_1$ are:

$$
\mathbf{T}_1 = \begin{bmatrix} 0.5 & 0.6 & 0.8 \\ 0.2 & 0.4 & 0.3 \\ 0.1 & 0.1 & 0.1 \end{bmatrix}, \quad \mathbf{G}_1 = \begin{bmatrix} 0.4 & 0.7 & 0.7 \\ 0.4 & 0.5 & 0.4 \\ 0.3 & 0.2 & 0.1 \end{bmatrix}
$$

The total number of elements is $N = 3 \times 3 = 9$.Calculate the absolute difference for each element:

$$
\begin{bmatrix} |0.5 - 0.4| & |0.6 - 0.7| & |0.8 - 0.7| \\ |0.2 - 0.4| & |0.4 - 0.5| & |0.3 - 0.4| \\ |0.1 - 0.3| & |0.1 - 0.2| & |0.1 - 0.1| \end{bmatrix} = \begin{bmatrix} 0.1 & 0.1 & 0.1 \\ 0.2 & 0.1 & 0.1 \\ 0.2 & 0.1 & 0.0 \end{bmatrix}
$$

Calculate the sum of all absolute differences:

$$
\text{Sum} = 0.1 + 0.1 + 0.1 + 0.2 + 0.1 + 0.1 + 0.2 + 0.1 + 0.0 = 1.0
$$

The L1 loss is the average of the absolute differences:

$$
L_1 = \frac{\text{Sum}}{N} = \frac{1.0}{9} \approx \mathbf{0.111}
$$

# Section 7 Reinforcement Learning

## Q1 2024 Dec C

![Q1](./2024DecC/3.png)
![Q1](./2024DecC/4.png)

## Q2 2023 May D

![Q2](./2023MayD/2.png)
![Q2](./2023MayD/3.png)

## Q3 2022 May 2

![Q3](./2022May2/1.png)
![Q3](./2022May2/2.png)
